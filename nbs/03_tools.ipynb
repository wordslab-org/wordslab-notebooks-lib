{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e82eac90-d637-49fc-a45f-b92d90cf97ab",
   "metadata": {},
   "source": [
    "# wordslab-notebooks-lib.tools\n",
    "\n",
    "> Predefined tools for LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0351acae-6611-498b-ab1b-66284dfd9ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T21:16:45.048565Z",
     "iopub.status.busy": "2026-02-03T21:16:45.048486Z",
     "iopub.status.idle": "2026-02-03T21:16:45.050796Z",
     "shell.execute_reply": "2026-02-03T21:16:45.050294Z",
     "shell.execute_reply.started": "2026-02-03T21:16:45.048557Z"
    }
   },
   "outputs": [],
   "source": [
    "#| default_exp tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d730a6-7fd4-497b-aaf7-a626b2206b94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:49:21.179497Z",
     "iopub.status.busy": "2026-02-03T23:49:21.179415Z",
     "iopub.status.idle": "2026-02-03T23:49:21.182138Z",
     "shell.execute_reply": "2026-02-03T23:49:21.181542Z",
     "shell.execute_reply.started": "2026-02-03T23:49:21.179491Z"
    }
   },
   "outputs": [],
   "source": [
    "#| exports\n",
    "from __future__ import annotations\n",
    "from enum import StrEnum, auto\n",
    "from typing import List, Dict, Any, Optional\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912bc5b3-10ff-4257-a516-1391dde396be",
   "metadata": {},
   "source": [
    "## Mistral vibe bultin tools\n",
    "\n",
    "The following tools code is inspired from **Mistral Vibe 2.0 (Apache 2.0 licence) :\n",
    "\n",
    "https://github.com/mistralai/mistral-vibe/tree/main/vibe/core/tools/builtins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d10dd-8af9-4bbc-a8b9-f9188175b78b",
   "metadata": {},
   "source": [
    "### Files tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938dc8cb-1682-4c31-a9cc-71ff56eccf8c",
   "metadata": {},
   "source": [
    "Utility functions for file access control (security measure):\n",
    "\n",
    "1. Find the project directory: parent git repository or current directory\n",
    "2. Check if the file path the LLM wants to access is located in inside the project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8355529b-cb78-4a69-b54f-b8490833fb5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:49:21.185554Z",
     "iopub.status.busy": "2026-02-03T23:49:21.185471Z",
     "iopub.status.idle": "2026-02-03T23:49:21.207880Z",
     "shell.execute_reply": "2026-02-03T23:49:21.206981Z",
     "shell.execute_reply.started": "2026-02-03T23:49:21.185548Z"
    }
   },
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "# Usage in Jupyterlab in wordslab notebooks\n",
    "if \"__notebook_path\" in globals():\n",
    "    STARTUP_DIR = (Path(os.environ[\"WORDSLAB_WORKSPACE\"]) / __notebook_path).parent\n",
    "# Usage in the command line\n",
    "else:\n",
    "    STARTUP_DIR = os.environ.get(\"PWD\", os.getcwd())\n",
    "\n",
    "def find_git_repo_root(start_path: Path | None = None) -> Path | None:\n",
    "    \"\"\"\n",
    "    Find the root directory of the git repository containing the given path.\n",
    "    \n",
    "    Searches upward from the given path (or current directory if None) until\n",
    "    finding a directory containing a .git subdirectory or file.\n",
    "    \n",
    "    Args:\n",
    "        start_path: Path to start searching from. If None, uses current directory.\n",
    "        \n",
    "    Returns:\n",
    "        Path to git repository root, or None if no git repository found.\n",
    "    \"\"\"\n",
    "    if start_path is None:\n",
    "        start_path = STARTUP_DIR\n",
    "    \n",
    "    start_path = Path(start_path).resolve()\n",
    "    \n",
    "    # Check if we're already in a git repo\n",
    "    current_dir = start_path\n",
    "    while True:\n",
    "        git_dir = current_dir / \".git\"\n",
    "        \n",
    "        # Check if .git exists as directory or file\n",
    "        if git_dir.exists():\n",
    "            # Verify it's actually a git repo by checking for HEAD file\n",
    "            head_file = git_dir / \"HEAD\" if git_dir.is_dir() else git_dir\n",
    "            if head_file.exists():\n",
    "                try:\n",
    "                    with open(head_file, 'r', encoding='utf-8') as f:\n",
    "                        head_content = f.read().strip()\n",
    "                        # Valid git HEAD should start with \"ref:\" or be a commit hash\n",
    "                        if head_content.startswith(\"ref:\") or len(head_content) == 40:\n",
    "                            return current_dir\n",
    "                except (OSError, UnicodeDecodeError):\n",
    "                    pass\n",
    "        \n",
    "        # Move up to parent directory\n",
    "        parent = current_dir.parent\n",
    "        if parent == current_dir:  # Reached root\n",
    "            return None\n",
    "        \n",
    "        current_dir = parent\n",
    "\n",
    "\n",
    "def get_project_root(start_path: Path | None = None) -> Path:\n",
    "    \"\"\"\n",
    "    Get the project root directory.\n",
    "    \n",
    "    First tries to find a git repository root. If none found, defaults to\n",
    "    current working directory.\n",
    "    \n",
    "    Returns:\n",
    "        Path to project root directory.\n",
    "    \"\"\"\n",
    "    git_root = find_git_repo_root(start_path)\n",
    "    if git_root is not None:\n",
    "        return git_root\n",
    "    \n",
    "    return start_path\n",
    "\n",
    "\n",
    "def is_path_in_project(path: Path, project_root: Path | None = None) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a path is within the project directory.\n",
    "    \n",
    "    Args:\n",
    "        path: Path to check\n",
    "        project_root: Project root directory. If None, uses get_project_root()\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_valid, error_message)\n",
    "        is_valid is True if path is within project root, False otherwise.\n",
    "        If is_valid is True, error_message is empty.\n",
    "        If is_valid is False, error_message contains a descriptive error.\n",
    "    \"\"\"\n",
    "    if project_root is None:\n",
    "        project_root = get_project_root()\n",
    "    \n",
    "    try:\n",
    "        path_resolved = path.resolve()\n",
    "        project_root_resolved = project_root.resolve()\n",
    "        \n",
    "        # Check if path is under project root\n",
    "        path.relative_to(project_root_resolved)\n",
    "        return True, \"\"\n",
    "    except ValueError:\n",
    "        return False, f\"Cannot access file outside project directory: {path}. Project root is {project_root_resolved}\"\n",
    "\n",
    "\n",
    "def validate_file_path(file_path: Path, project_root: Path | None = None) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Validate that a file path is within the project directory.\n",
    "    \n",
    "    Args:\n",
    "        file_path: File path to validate\n",
    "        project_root: Project root directory. If None, uses get_project_root()\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (is_valid, error_message)\n",
    "        If is_valid is True, error_message is empty.\n",
    "        If is_valid is False, error_message contains a descriptive error.\n",
    "    \"\"\"\n",
    "    if project_root is None:\n",
    "        project_root = get_project_root()\n",
    "    \n",
    "    file_path_resolved = file_path.resolve()\n",
    "    project_root_resolved = project_root.resolve()\n",
    "    \n",
    "    # Check if file is within project\n",
    "    try:\n",
    "        file_path.relative_to(project_root_resolved)\n",
    "    except ValueError:\n",
    "        return False, f\"Cannot access file outside project directory: {file_path}. Project root is {project_root_resolved}\"\n",
    "    \n",
    "    # Check if path exists\n",
    "    if not file_path.exists():\n",
    "        return False, f\"File not found at: {file_path}. Please check the path and try again.\"\n",
    "    \n",
    "    # Check if it's a file (not directory)\n",
    "    if not file_path.is_file():\n",
    "        return False, f\"Path is a directory, not a file: {file_path}. Please provide a file path.\"\n",
    "    \n",
    "    return True, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40662c31-5512-4083-965a-46763bec5ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:49:21.208120Z",
     "iopub.status.busy": "2026-02-03T23:49:21.208054Z",
     "iopub.status.idle": "2026-02-03T23:49:21.223711Z",
     "shell.execute_reply": "2026-02-03T23:49:21.223069Z",
     "shell.execute_reply.started": "2026-02-03T23:49:21.208114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/workspace/wordslab-notebooks-lib/nbs')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STARTUP_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14beb2f8-0696-4543-9a15-21933e111562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:49:21.404516Z",
     "iopub.status.busy": "2026-02-03T23:49:21.404437Z",
     "iopub.status.idle": "2026-02-03T23:49:21.408229Z",
     "shell.execute_reply": "2026-02-03T23:49:21.407318Z",
     "shell.execute_reply.started": "2026-02-03T23:49:21.404509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/workspace/wordslab-notebooks-lib')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_project_root()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd31bb4-7e94-4d67-acc5-9a5efa60afef",
   "metadata": {},
   "source": [
    "File management tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f75e8d2c-a490-485d-a94d-654586ec1f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:49:23.292864Z",
     "iopub.status.busy": "2026-02-03T23:49:23.292772Z",
     "iopub.status.idle": "2026-02-03T23:49:23.305435Z",
     "shell.execute_reply": "2026-02-03T23:49:23.305019Z",
     "shell.execute_reply.started": "2026-02-03T23:49:23.292856Z"
    }
   },
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "# ============================================================================\n",
    "# File Reading Tool\n",
    "# ============================================================================\n",
    "\n",
    "def read_file(\n",
    "    path: str,  # Path to the file to read\n",
    "    offset: int = 0,  # Line number to start reading from (0-indexed, inclusive) (default: 0)\n",
    "    limit: Optional[int] = None  # Maximum number of lines to read (default: None)\n",
    ") -> str:  # JSON string with file content or error\n",
    "    \"\"\"\n",
    "    Read a UTF-8 file and return content as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each read operation is independent\n",
    "    - **Large file handling**: Automatically handles large files with byte limits\n",
    "    - **Line-based reading**: Use offset and limit for efficient navigation\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - By default, reads from the beginning of the file (offset=0)\n",
    "    - Use offset (line number) and limit (number of lines) to read specific parts\n",
    "    - The result includes was_truncated: true if content was cut short\n",
    "    - For large files, read in chunks: first with limit, then with offset\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If file not found, check the path is correct\n",
    "    - If path is a directory, provide a file path instead\n",
    "    - If offset is negative, use a non-negative value\n",
    "    - If limit is not positive, use a value greater than 0\n",
    "    - If reading fails, check file permissions\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - offset: 0 (read from beginning of file)\n",
    "    - limit: None (read entire file)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"content\": \"file content\",\n",
    "        \"lines_read\": number of lines read,\n",
    "        \"was_truncated\": true/false (if reading was stopped due to limit)\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not path.strip():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Path cannot be empty. Please provide a valid file path.\"\n",
    "            })\n",
    "        \n",
    "        if offset < 0:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Offset cannot be negative. Please use a non-negative value.\"\n",
    "            })\n",
    "        \n",
    "        if limit is not None and limit <= 0:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Limit must be a positive number. Please use a value greater than 0.\"\n",
    "            })\n",
    "        \n",
    "        # Resolve file path\n",
    "        file_path = Path(path).expanduser().resolve()\n",
    "\n",
    "        # Validate file is in the project directory and is readable        \n",
    "        is_valid, error_message = validate_file_path(file_path)\n",
    "        if not is_valid:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": error_message\n",
    "            })\n",
    "            \n",
    "        # Read file content\n",
    "        lines_to_return: List[str] = []\n",
    "        bytes_read = 0\n",
    "        was_truncated = False\n",
    "        max_read_bytes = 64_000  # Same as Mistral Vibe default\n",
    "        \n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            line_index = 0\n",
    "            for line in f:\n",
    "                if line_index < offset:\n",
    "                    line_index += 1\n",
    "                    continue\n",
    "                \n",
    "                if limit is not None and len(lines_to_return) >= limit:\n",
    "                    was_truncated = True\n",
    "                    break\n",
    "                \n",
    "                line_bytes = len(line.encode('utf-8'))\n",
    "                if bytes_read + line_bytes > max_read_bytes:\n",
    "                    was_truncated = True\n",
    "                    break\n",
    "                \n",
    "                lines_to_return.append(line)\n",
    "                bytes_read += line_bytes\n",
    "                line_index += 1\n",
    "        \n",
    "        content = \"\".join(lines_to_return)\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"content\": content,\n",
    "            \"lines_read\": len(lines_to_return),\n",
    "            \"was_truncated\": was_truncated\n",
    "        })\n",
    "        \n",
    "    except UnicodeDecodeError as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Unicode decode error reading {path}: {str(e)}. Please check if the file is a binary file.\"\n",
    "        })\n",
    "    \n",
    "    except PermissionError:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Permission denied reading file: {path}. Please check your permissions and try again.\"\n",
    "        })\n",
    "    \n",
    "    except OSError as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Error reading file {path}: {str(e)}. Please check the file path and your permissions.\"\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"An unexpected error occurred while reading {path}: {str(e)}. Please try again.\"\n",
    "        })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# File Writing Tool\n",
    "# ============================================================================\n",
    "\n",
    "def write_file(\n",
    "    path: str,  # Path to the file to write\n",
    "    content: str,  # Content to write to the file\n",
    "    overwrite: bool = False  # Must be set to true to overwrite an existing file (default: False)\n",
    ") -> str:  # JSON string with write result or error\n",
    "    \"\"\"\n",
    "    Create or overwrite a UTF-8 file and return result as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Safety first**: By default, fails if file exists to prevent accidental data loss\n",
    "    - **Size limits**: Content is limited to 64KB to prevent large file operations\n",
    "    - **User confirmation**: Requires explicit confirmation before writing (except for new files)\n",
    "    - **Path validation**: Validates paths are within the project directory\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - To create a new file, just provide path and content (overwrite defaults to false)\n",
    "    - To overwrite an existing file, set overwrite=True\n",
    "    - Parent directories are created automatically if needed\n",
    "    - Always use read_file first to understand existing content before overwriting\n",
    "    - Prefer search_replace over write_file for editing existing files\n",
    "    - Avoid creating documentation files (*.md) or README files unless explicitly requested\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If file exists and overwrite=False, set overwrite=True to replace it\n",
    "    - If path is empty, provide a valid file path\n",
    "    - If content is empty, provide content to write\n",
    "    - If content exceeds 64KB, reduce the content size\n",
    "    - If permission denied, check your write permissions\n",
    "    - If trying to write outside project directory, use a path within the project\n",
    "    - If user cancels the operation, don't retry without user confirmation\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - overwrite: False (fail if file exists, set to True to overwrite)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"file_existed\": true/false (whether file existed before writing),\n",
    "        \"bytes_written\": number of bytes written,\n",
    "        \"message\": \"success message\"\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not path.strip():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Path cannot be empty. Please provide a valid file path.\"\n",
    "            })\n",
    "        \n",
    "        if not content.strip():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Content cannot be empty. Please provide content to write.\"\n",
    "            })\n",
    "        \n",
    "        content_bytes = len(content.encode('utf-8'))\n",
    "        max_write_bytes = 64_000  # Same as Mistral Vibe default\n",
    "        \n",
    "        if content_bytes > max_write_bytes:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Content exceeds {max_write_bytes} bytes limit. Please reduce the content size.\"\n",
    "            })\n",
    "        \n",
    "        # Resolve file path\n",
    "        file_path = Path(path).expanduser().resolve()\n",
    "\n",
    "        # Validate we're not writing outside project directory       \n",
    "        is_valid, error_message = is_path_in_project(file_path)\n",
    "        if not is_valid:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": error_message\n",
    "            })\n",
    "        \n",
    "        # Check if file exists\n",
    "        file_existed = file_path.exists()\n",
    "        \n",
    "        if file_existed and not overwrite:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"File '{file_path}' already exists. Set overwrite=True to replace the existing file.\"\n",
    "            })\n",
    "        \n",
    "        # Ask for user confirmation before writing\n",
    "        # This matches the Mistral Vibe behavior\n",
    "        response = input(f\"\\n⚠️  Warning: About to write to file '{file_path}'.\\nDo you want to proceed? (yes/no): \").strip().lower()\n",
    "        if response not in ['yes', 'y']:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"File write to '{file_path}' was cancelled by user.\"\n",
    "            })\n",
    "        \n",
    "        # Create parent directories if needed\n",
    "        file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Write file\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        \n",
    "        action = \"Overwritten\" if file_existed else \"Created\"\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"file_existed\": file_existed,\n",
    "            \"bytes_written\": content_bytes,\n",
    "            \"message\": f\"{action} file {file_path}\"\n",
    "        })\n",
    "        \n",
    "    except PermissionError:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Permission denied writing to file: {path}. Please check your permissions.\"\n",
    "        })\n",
    "    \n",
    "    except OSError as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"OS error writing to {path}: {str(e)}. Please check the file path and your permissions.\"\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"An unexpected error occurred while writing {path}: {str(e)}. Please try again.\"\n",
    "        })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# File Search Tool (Grep)\n",
    "# ============================================================================\n",
    "\n",
    "def grep(\n",
    "    pattern: str,  # Search pattern (regex)\n",
    "    path: str = \".\",  # Path to search in (default: \".\")\n",
    "    max_matches: Optional[int] = None,  # Maximum number of matches to return (default: None)\n",
    "    use_default_ignore: bool = True  # Whether to respect .gitignore and .ignore files (default: True)\n",
    ") -> str:  # JSON string with search results or error\n",
    "    \"\"\"\n",
    "    Recursively search files for a regex pattern and return results as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Fast search**: Very fast and automatically ignores common files and directories\n",
    "    - **Regex support**: Supports full regular expression patterns\n",
    "    - **Smart defaults**: Automatically ignores .pyc files, .venv directories, etc.\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use this to find where functions are defined, how variables are used, or to locate specific error messages\n",
    "    - Search in current directory by default (path=\".\")\n",
    "    - Return all matches by default (max_matches=None)\n",
    "    - Respect .gitignore and .ignore files by default (use_default_ignore=True)\n",
    "    - For large codebases, limit max_matches to avoid overwhelming output\n",
    "    - Use specific patterns for better results\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If empty pattern provided, provide a valid search pattern\n",
    "    - If path doesn't exist, check the path and try again\n",
    "    - If permission denied, check your read permissions\n",
    "    - If pattern is too broad, narrow it down\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - path: \".\" (search in current directory)\n",
    "    - max_matches: None (return all matches)\n",
    "    - use_default_ignore: True (respect .gitignore and .ignore files)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"matches\": \"string containing all matches with file paths and line numbers\",\n",
    "        \"match_count\": number of matches found,\n",
    "        \"was_truncated\": true/false (if output was cut short by limits)\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not pattern.strip():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Empty search pattern provided. Please provide a valid search pattern.\"\n",
    "            })\n",
    "        \n",
    "        # Resolve search path\n",
    "        search_path = Path(path).expanduser().resolve()\n",
    "\n",
    "        # Validate we're not searching outside project directory       \n",
    "        is_valid, error_message = is_path_in_project(file_path)\n",
    "        if not is_valid:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": error_message\n",
    "            })\n",
    "        \n",
    "        # Validate path exists\n",
    "        if not search_path.exists():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Path does not exist: {path}. Please check the path and try again.\"\n",
    "            })\n",
    "        \n",
    "        # Default max matches\n",
    "        default_max_matches = 100\n",
    "        max_matches = max_matches or default_max_matches\n",
    "        \n",
    "        # Default exclude patterns\n",
    "        exclude_patterns = [\n",
    "            \".venv/\",\n",
    "            \"venv/\",\n",
    "            \".env/\",\n",
    "            \"env/\",\n",
    "            \"node_modules/\",\n",
    "            \".git/\",\n",
    "            \"__pycache__/\",\n",
    "            \".pytest_cache/\",\n",
    "            \".mypy_cache/\",\n",
    "            \".tox/\",\n",
    "            \".nox/\",\n",
    "            \".coverage/\",\n",
    "            \"htmlcov/\",\n",
    "            \"dist/\",\n",
    "            \"build/\",\n",
    "            \".idea/\",\n",
    "            \".vscode/\",\n",
    "            \"*.egg-info\",\n",
    "            \"*.pyc\",\n",
    "            \"*.pyo\",\n",
    "            \"*.pyd\",\n",
    "            \".DS_Store\",\n",
    "            \"Thumbs.db\",\n",
    "        ]\n",
    "        \n",
    "        # Load additional patterns from .vibeignore if it exists\n",
    "        codeignore_path = get_project_root() / \".vibeignore\"\n",
    "        if codeignore_path.is_file():\n",
    "            try:\n",
    "                with open(codeignore_path, 'r', encoding='utf-8') as f:\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        if line and not line.startswith(\"#\"):\n",
    "                            exclude_patterns.append(line)\n",
    "            except OSError:\n",
    "                pass\n",
    "        \n",
    "        # Build grep command\n",
    "        import subprocess\n",
    "        \n",
    "        cmd = [\n",
    "            \"grep\",\n",
    "            \"-r\",\n",
    "            \"-n\",\n",
    "            \"-I\",\n",
    "            \"-E\",\n",
    "            f\"--max-count={max_matches + 1}\",  # +1 to detect truncation\n",
    "            \"-e\",\n",
    "            pattern,\n",
    "            str(search_path)\n",
    "        ]\n",
    "        \n",
    "        # Add exclude patterns\n",
    "        for pattern in exclude_patterns:\n",
    "            if pattern.endswith(\"/\"):\n",
    "                dir_pattern = pattern.rstrip(\"/\")\n",
    "                cmd.append(f\"--exclude-dir={dir_pattern}\")\n",
    "            else:\n",
    "                cmd.append(f\"--exclude={pattern}\")\n",
    "        \n",
    "        # Execute grep\n",
    "        result = subprocess.run(\n",
    "            cmd,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True,\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if result.returncode not in {0, 1}:\n",
    "            error_msg = result.stderr or f\"Process exited with code {result.returncode}\"\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"grep error: {error_msg}. Please check your search pattern and try again.\"\n",
    "            })\n",
    "        \n",
    "        stdout = result.stdout\n",
    "        output_lines = stdout.splitlines() if stdout else []\n",
    "        \n",
    "        # Apply truncation\n",
    "        truncated_lines = output_lines[:max_matches]\n",
    "        truncated_output = \"\\n\".join(truncated_lines)\n",
    "        \n",
    "        was_truncated = len(output_lines) > max_matches\n",
    "        \n",
    "        max_output_bytes = 64_000  # Same as Mistral Vibe default\n",
    "        if len(truncated_output) > max_output_bytes:\n",
    "            truncated_output = truncated_output[:max_output_bytes]\n",
    "            was_truncated = True\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"matches\": truncated_output,\n",
    "            \"match_count\": len(truncated_lines),\n",
    "            \"was_truncated\": was_truncated\n",
    "        })\n",
    "        \n",
    "    except subprocess.TimeoutExpired:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": \"Search timed out after 60 seconds. Please try a more specific search pattern or reduce the search scope.\"\n",
    "        })\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": \"grep command not found. Please install grep and try again.\"\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"An error occurred while searching: {str(e)}. Please check your search pattern and try again.\"\n",
    "        })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Helper Functions\n",
    "# ============================================================================\n",
    "\n",
    "SEARCH_REPLACE_BLOCK_RE = re.compile(\n",
    "    r\"<{5,} SEARCH\\r?\\n(.*?)\\r?\\n?={5,}\\r?\\n(.*?)\\r?\\n?>{5,} REPLACE\", flags=re.DOTALL\n",
    ")\n",
    "\n",
    "SEARCH_REPLACE_BLOCK_WITH_FENCE_RE = re.compile(\n",
    "    r\"```[\\s\\S]*?\\n<{5,} SEARCH\\r?\\n(.*?)\\r?\\n?={5,}\\r?\\n(.*?)\\r?\\n?>{5,} REPLACE\\s*\\n```\",\n",
    "    flags=re.DOTALL,\n",
    ")\n",
    "\n",
    "\n",
    "def _parse_search_replace_blocks(content: str) -> List[tuple]:\n",
    "    \"\"\"Parse SEARCH/REPLACE blocks from content.\n",
    "    \n",
    "    Supports two formats:\n",
    "    1. With code block fences (```...```)\n",
    "    2. Without code block fences\n",
    "    \"\"\"\n",
    "    matches = SEARCH_REPLACE_BLOCK_WITH_FENCE_RE.findall(content)\n",
    "    \n",
    "    if not matches:\n",
    "        matches = SEARCH_REPLACE_BLOCK_RE.findall(content)\n",
    "    \n",
    "    return [\n",
    "        (search.rstrip(\"\\r\\n\"), replace.rstrip(\"\\r\\n\"))\n",
    "        for search, replace in matches\n",
    "    ]\n",
    "\n",
    "\n",
    "def _find_search_context(content: str, search_text: str, max_context: int = 5) -> str:\n",
    "    \"\"\"Find context around search text for debugging.\"\"\"\n",
    "    lines = content.split(\"\\n\")\n",
    "    search_lines = search_text.split(\"\\n\")\n",
    "    \n",
    "    if not search_lines:\n",
    "        return \"Search text is empty\"\n",
    "    \n",
    "    first_search_line = search_lines[0].strip()\n",
    "    if not first_search_line:\n",
    "        return \"First line of search text is empty or whitespace only\"\n",
    "    \n",
    "    matches = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if first_search_line in line:\n",
    "            matches.append(i)\n",
    "    \n",
    "    if not matches:\n",
    "        return f\"First search line '{first_search_line}' not found anywhere in file\"\n",
    "    \n",
    "    context_lines = []\n",
    "    for match_idx in matches[:3]:\n",
    "        start = max(0, match_idx - max_context)\n",
    "        end = min(len(lines), match_idx + max_context + 1)\n",
    "        \n",
    "        context_lines.append(f\"\\nPotential match area around line {match_idx + 1}:\")\n",
    "        for i in range(start, end):\n",
    "            marker = \">>>\" if i == match_idx else \"   \"\n",
    "            context_lines.append(f\"{marker} {i + 1:3d}: {lines[i]}\")\n",
    "    \n",
    "    return \"\\n\".join(context_lines)\n",
    "\n",
    "    \n",
    "# ============================================================================\n",
    "# File Search and Replace Tool\n",
    "# ============================================================================\n",
    "\n",
    "def search_replace(\n",
    "    file_path: str,  # Path to the file to modify\n",
    "    content: str  # SEARCH/REPLACE blocks with format:\n",
    "    # <<<<<<< SEARCH\n",
    "    # [replacement text]\n",
    "    # =======\n",
    "    # [replacement text]\n",
    "    # >>>>>> REPLACE\n",
    ") -> str:  # JSON string with search/replace result or error\n",
    "    \"\"\"\n",
    "    Replace sections of files using SEARCH/REPLACE blocks and return result as JSON.\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"blocks_applied\": number of blocks successfully applied,\n",
    "        \"lines_changed\": number of lines changed,\n",
    "        \"warnings\": [list of warnings],\n",
    "        \"message\": \"success message\"\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not file_path.strip():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"File path cannot be empty. Please provide a valid file path.\"\n",
    "            })\n",
    "        \n",
    "        if not content.strip():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Content cannot be empty. Please provide SEARCH/REPLACE blocks.\"\n",
    "            })\n",
    "        \n",
    "        max_content_size = 100_000\n",
    "        if len(content) > max_content_size:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Content size ({len(content)} bytes) exceeds max_content_size ({max_content_size} bytes). Please reduce the content size.\"\n",
    "            })\n",
    "        \n",
    "        # Resolve file path\n",
    "        file_path_obj = Path(file_path).expanduser().resolve()\n",
    "        \n",
    "        # Validate file is in the project directory and is readable        \n",
    "        is_valid, error_message = validate_file_path(file_path_obj)\n",
    "        if not is_valid:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": error_message\n",
    "            })\n",
    "        \n",
    "        # Read original content\n",
    "        with open(file_path_obj, 'r', encoding='utf-8') as f:\n",
    "            original_content = f.read()\n",
    "        \n",
    "        # Parse SEARCH/REPLACE blocks\n",
    "        search_replace_blocks = _parse_search_replace_blocks(content)\n",
    "        \n",
    "        if not search_replace_blocks:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"No valid SEARCH/REPLACE blocks found in content.\\n\"\n",
    "                       \"Expected format:\\n\"\n",
    "                       \"<<<<<<< SEARCH\\n\"\n",
    "                       \"[exact content to find]\\n\"\n",
    "                       \"=======\\n\"\n",
    "                       \"[new content to replace with]\\n\"\n",
    "                       \">>>>>> REPLACE\"\n",
    "            })\n",
    "        \n",
    "        # Apply blocks\n",
    "        applied = 0\n",
    "        errors: List[str] = []\n",
    "        warnings: List[str] = []\n",
    "        current_content = original_content\n",
    "        \n",
    "        for i, (search, replace) in enumerate(search_replace_blocks, 1):\n",
    "            if search not in current_content:\n",
    "                context = _find_search_context(current_content, search)\n",
    "                error_msg = (\n",
    "                    f\"SEARCH/REPLACE block {i} failed: Search text not found in {file_path}\\n\"\n",
    "                    f\"Search text was:\\n{search!r}\\n\"\n",
    "                    f\"Context analysis:\\n{context}\\n\"\n",
    "                    \"Debugging tips:\\n\"\n",
    "                    \"1. Check for exact whitespace/indentation match\\n\"\n",
    "                    \"2. Verify line endings match the file exactly (\\\\r\\\\n vs \\\\n)\\n\"\n",
    "                    \"3. Ensure the search text hasn't been modified by previous blocks or user edits\\n\"\n",
    "                    \"4. Check for typos or case sensitivity issues\"\n",
    "                )\n",
    "                errors.append(error_msg)\n",
    "                continue\n",
    "            \n",
    "            occurrences = current_content.count(search)\n",
    "            if occurrences > 1:\n",
    "                warning_msg = (\n",
    "                    f\"Search text in block {i} appears {occurrences} times in the file. \"\n",
    "                    f\"Only the first occurrence will be replaced. Consider making your \"\n",
    "                    f\"search pattern more specific to avoid unintended changes.\"\n",
    "                )\n",
    "                warnings.append(warning_msg)\n",
    "            \n",
    "            current_content = current_content.replace(search, replace, 1)\n",
    "            applied += 1\n",
    "        \n",
    "        if errors:\n",
    "            error_message = \"SEARCH/REPLACE blocks failed:\\n\" + \"\\n\\n\".join(errors)\n",
    "            if warnings:\n",
    "                error_message += \"\\n\\nWarnings encountered:\\n\" + \"\\n\".join(warnings)\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": error_message\n",
    "            })\n",
    "        \n",
    "        # Calculate line changes\n",
    "        if current_content == original_content:\n",
    "            lines_changed = 0\n",
    "        else:\n",
    "            original_lines = len(original_content.splitlines())\n",
    "            new_lines = len(current_content.splitlines())\n",
    "            lines_changed = new_lines - original_lines\n",
    "        \n",
    "        # Ask for user confirmation before modifying file\n",
    "        # This matches the Mistral Vibe behavior\n",
    "        response = input(f\"\\n⚠️  Warning: About to modify file '{file_path_obj}'.\\nDo you want to proceed? (yes/no): \").strip().lower()\n",
    "        if response not in ['yes', 'y']:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"File modification of '{file_path}' was cancelled by user.\"\n",
    "            })\n",
    "        \n",
    "        # Write modified content\n",
    "        with open(file_path_obj, 'w', encoding='utf-8') as f:\n",
    "            f.write(current_content)\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"blocks_applied\": applied,\n",
    "            \"lines_changed\": lines_changed,\n",
    "            \"warnings\": warnings,\n",
    "            \"message\": f\"Applied {applied} block{'s' if applied != 1 else ''} to {file_path}\"\n",
    "        })\n",
    "        \n",
    "    except UnicodeDecodeError as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Unicode decode error reading {file_path}: {str(e)}. Please check if the file is a binary file.\"\n",
    "        })\n",
    "    \n",
    "    except PermissionError:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"Permission denied reading/writing file: {file_path}. Please check your permissions.\"\n",
    "        })\n",
    "    \n",
    "    except OSError as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"OS error accessing {file_path}: {str(e)}. Please check the file path and your permissions.\"\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"error\": f\"An unexpected error occurred while modifying {file_path}: {str(e)}. Please try again.\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068dfbf1-1be7-4e31-8ca1-9d96f5acb944",
   "metadata": {},
   "source": [
    "Tests for file access control utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a914991-cf24-4d51-a8d4-05f1dec99d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "def test_find_git_repo_root_in_git_repo():\n",
    "    \"\"\"Test finding git repo root when in a git repository.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        repo_dir = Path(tmpdir) / \"repo\"\n",
    "        repo_dir.mkdir()\n",
    "        \n",
    "        # Initialize git repo\n",
    "        os.chdir(repo_dir)\n",
    "        os.system(\"git init\")\n",
    "        os.system(\"git config user.email 'test@test.com'\")\n",
    "        os.system(\"git config user.name 'Test User'\")\n",
    "        \n",
    "        # Create a file and commit\n",
    "        test_file = repo_dir / \"test.txt\"\n",
    "        test_file.write_text(\"test content\")\n",
    "        os.system(\"git add test.txt\")\n",
    "        os.system(\"git commit -m 'Initial commit'\")\n",
    "        \n",
    "        # Test finding repo root from repo root\n",
    "        result = find_git_repo_root(repo_dir)\n",
    "        assert result == repo_dir\n",
    "        \n",
    "        # Test finding repo root from subdirectory\n",
    "        subdir = repo_dir / \"subdir\"\n",
    "        subdir.mkdir()\n",
    "        result = find_git_repo_root(subdir)\n",
    "        assert result == repo_dir\n",
    "\n",
    "\n",
    "def test_find_git_repo_root_not_in_git_repo():\n",
    "    \"\"\"Test finding git repo root when not in a git repository.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        non_repo_dir = Path(tmpdir) / \"non_repo\"\n",
    "        non_repo_dir.mkdir()\n",
    "        \n",
    "        result = find_git_repo_root(non_repo_dir)\n",
    "        assert result is None\n",
    "\n",
    "\n",
    "def test_get_project_root_in_git_repo():\n",
    "    \"\"\"Test getting project root when in a git repository.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        repo_dir = Path(tmpdir) / \"repo\"\n",
    "        repo_dir.mkdir()\n",
    "        \n",
    "        # Initialize git repo\n",
    "        os.chdir(repo_dir)\n",
    "        os.system(\"git init\")\n",
    "        os.system(\"git config user.email 'test@test.com'\")\n",
    "        os.system(\"git config user.name 'Test User'\")\n",
    "        \n",
    "        # Create a subdir\n",
    "        file_dir = repo_dir / \"subdir\"\n",
    "        file_dir.mkdir()\n",
    "        \n",
    "        # Test getting project root\n",
    "        result = get_project_root(file_dir)\n",
    "        assert result == repo_dir\n",
    "\n",
    "\n",
    "def test_get_project_root_not_in_git_repo():\n",
    "    \"\"\"Test getting project root when not in a git repository.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        non_repo_dir = Path(tmpdir) / \"non_repo\"\n",
    "        non_repo_dir.mkdir()        \n",
    "        \n",
    "        result = get_project_root(non_repo_dir)\n",
    "        print(result)\n",
    "        assert result == non_repo_dir\n",
    "\n",
    "\n",
    "def test_is_path_in_project():\n",
    "    \"\"\"Test checking if a path is within the project directory.\"\"\"\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        repo_dir = Path(tmpdir) / \"repo\"\n",
    "        repo_dir.mkdir()\n",
    "        \n",
    "        # Initialize git repo\n",
    "        os.chdir(repo_dir)\n",
    "        os.system(\"git init\")\n",
    "        os.system(\"git config user.email 'test@test.com'\")\n",
    "        os.system(\"git config user.name 'Test User'\")\n",
    "\n",
    "        \n",
    "        # Test path within project        \n",
    "        test_file = repo_dir / \"test.txt\"\n",
    "        is_valid, error_message = is_path_in_project(test_file, project_root=repo_dir)\n",
    "        assert is_valid\n",
    "        \n",
    "        # Test path outside project\n",
    "        outside_file = Path(tmpdir) / \"outside.txt\"\n",
    "        is_valid, error_message = is_path_in_project(outside_file, project_root=repo_dir)\n",
    "        assert not is_valid\n",
    "\n",
    "test_find_git_repo_root_in_git_repo()\n",
    "test_find_git_repo_root_not_in_git_repo()\n",
    "test_get_project_root_in_git_repo()\n",
    "test_get_project_root_not_in_git_repo()\n",
    "test_is_path_in_project()\n",
    "print(\"All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4f029-c9b6-49ce-8d86-83bef2ddbeb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T22:01:11.394417Z",
     "iopub.status.busy": "2026-01-31T22:01:11.394321Z",
     "iopub.status.idle": "2026-01-31T22:01:11.398089Z",
     "shell.execute_reply": "2026-01-31T22:01:11.396507Z",
     "shell.execute_reply.started": "2026-01-31T22:01:11.394410Z"
    }
   },
   "source": [
    "Test file management tools.\n",
    "\n",
    "These tests verify that the simple file management tools work correctly and return proper JSON responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416a27ed-1c33-45e6-b99e-2d5e3e4acc27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:57:37.487604Z",
     "iopub.status.busy": "2026-02-03T23:57:37.487515Z",
     "iopub.status.idle": "2026-02-03T23:57:37.532900Z",
     "shell.execute_reply": "2026-02-03T23:57:37.532165Z",
     "shell.execute_reply.started": "2026-02-03T23:57:37.487598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': False, 'error': 'Error reading file nonexistent_file.txt: [Errno 2] No such file or directory. Please check the file path and your permissions.'}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 402\u001b[39m\n\u001b[32m    400\u001b[39m testReadFile.test_read_file_with_limit()\n\u001b[32m    401\u001b[39m testReadFile.test_read_file_empty_path()\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m \u001b[43mtestReadFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest_read_file_not_found\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m testReadFile.test_read_file_is_directory()\n\u001b[32m    404\u001b[39m testReadFile.test_read_file_negative_offset()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mTestReadFile.test_read_file_not_found\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m data[\u001b[33m\"\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnot found\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data[\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m].lower()\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "class TestReadFile:\n",
    "    \"\"\"Test read_file function.\"\"\"\n",
    "    \n",
    "    def test_read_file_success(self):\n",
    "        \"\"\"Test successful file reading.\"\"\"\n",
    "        # Create a temporary file\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', dir=STARTUP_DIR) as f:\n",
    "            f.write(\"Line 1\\nLine 2\\nLine 3\\nLine 4\\nLine 5\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = read_file(temp_path)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert \"Line 1\" in data[\"content\"]\n",
    "            assert data[\"lines_read\"] == 5\n",
    "            assert data[\"was_truncated\"] is False\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_read_file_with_offset(self):\n",
    "        \"\"\"Test reading file with offset.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', dir=STARTUP_DIR) as f:\n",
    "            f.write(\"Line 1\\nLine 2\\nLine 3\\nLine 4\\nLine 5\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = read_file(temp_path, offset=2)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert \"Line 1\" not in data[\"content\"]\n",
    "            assert \"Line 3\" in data[\"content\"]\n",
    "            assert data[\"lines_read\"] == 3\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_read_file_with_limit(self):\n",
    "        \"\"\"Test reading file with limit.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', dir=STARTUP_DIR) as f:\n",
    "            f.write(\"Line 1\\nLine 2\\nLine 3\\nLine 4\\nLine 5\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = read_file(temp_path, limit=3)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"lines_read\"] == 3\n",
    "            assert data[\"was_truncated\"] is True\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_read_file_empty_path(self):\n",
    "        \"\"\"Test reading with empty path.\"\"\"\n",
    "        result = read_file(\"\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"empty\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_read_file_not_found(self):\n",
    "        \"\"\"Test reading non-existent file.\"\"\"\n",
    "        result = read_file(\"nonexistent_file.txt\")\n",
    "        data = json.loads(result)\n",
    "        print(data)\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"not found\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_read_file_is_directory(self):\n",
    "        \"\"\"Test reading a directory.\"\"\"\n",
    "        result = read_file(\".\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"directory\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_read_file_negative_offset(self):\n",
    "        \"\"\"Test reading with negative offset.\"\"\"\n",
    "        result = read_file(\"test.txt\", offset=-1)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"negative\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_read_file_invalid_limit(self):\n",
    "        \"\"\"Test reading with invalid limit.\"\"\"\n",
    "        result = read_file(\"test.txt\", limit=0)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"positive\" in data[\"error\"].lower()\n",
    "\n",
    "\n",
    "class TestWriteFile:\n",
    "    \"\"\"Test write_file function.\"\"\"\n",
    "    \n",
    "    def test_write_file_success(self):\n",
    "        \"\"\"Test successful file writing.\"\"\"\n",
    "        temp_path = \"test_success.txt\"\n",
    "        \n",
    "        result = write_file(temp_path, \"Hello World\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert data[\"file_existed\"] is False\n",
    "        assert data[\"bytes_written\"] == 11\n",
    "        assert Path(temp_path).exists()\n",
    "        \n",
    "        # Clean up\n",
    "        os.unlink(temp_path)\n",
    "    \n",
    "    def test_write_file_overwrite(self):\n",
    "        \"\"\"Test file overwriting.\"\"\"\n",
    "        # Create a file in the current directory\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', dir='.') as f:\n",
    "            f.write(\"Original content\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = write_file(temp_path, \"New content\", overwrite=True)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"file_existed\"] is True\n",
    "            assert data[\"bytes_written\"] == 11  # \"New content\" is 11 bytes\n",
    "            \n",
    "            # Verify content was overwritten\n",
    "            with open(temp_path, 'r') as f:\n",
    "                content = f.read()\n",
    "            assert content == \"New content\"\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_write_file_no_overwrite(self):\n",
    "        \"\"\"Test file writing without overwrite flag.\"\"\"\n",
    "        # Create a file in the current directory\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt', dir='.') as f:\n",
    "            f.write(\"Original content\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = write_file(temp_path, \"New content\")\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is False\n",
    "            assert \"exists\" in data[\"error\"].lower()\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_write_file_empty_path(self):\n",
    "        \"\"\"Test writing with empty path.\"\"\"\n",
    "        result = write_file(\"\", \"content\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"empty\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_write_file_empty_content(self):\n",
    "        \"\"\"Test writing with empty content.\"\"\"\n",
    "        result = write_file(\"test.txt\", \"\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"empty\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_write_file_too_large(self):\n",
    "        \"\"\"Test writing content that's too large.\"\"\"\n",
    "        large_content = \"x\" * 70_000\n",
    "        result = write_file(\"test.txt\", large_content)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"exceeds\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_write_file_outside_project(self):\n",
    "        \"\"\"Test writing outside project directory.\"\"\"\n",
    "        result = write_file(\"/tmp/outside_project.txt\", \"content\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"outside\" in data[\"error\"].lower()\n",
    "\n",
    "\n",
    "class TestGrep:\n",
    "    \"\"\"Test grep function.\"\"\"\n",
    "    \n",
    "    def test_grep_success(self):\n",
    "        \"\"\"Test successful grep search.\"\"\"\n",
    "        # Create a temporary file with content\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(\"apple\\nbanana\\napple\\norange\\napple\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = grep(\"apple\", temp_path)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"match_count\"] == 3\n",
    "            assert \"apple\" in data[\"matches\"]\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_grep_no_matches(self):\n",
    "        \"\"\"Test grep with no matches.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(\"apple\\nbanana\\norange\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = grep(\"zebra\", temp_path)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"match_count\"] == 0\n",
    "            assert data[\"matches\"] == \"\"\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_grep_with_max_matches(self):\n",
    "        \"\"\"Test grep with max matches limit.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(\"apple\\nbanana\\napple\\norange\\napple\\napple\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            result = grep(\"apple\", temp_path, max_matches=2)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"match_count\"] == 2\n",
    "            assert data[\"was_truncated\"] is True\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_grep_empty_pattern(self):\n",
    "        \"\"\"Test grep with empty pattern.\"\"\"\n",
    "        result = grep(\"\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"empty\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_grep_path_not_found(self):\n",
    "        \"\"\"Test grep with non-existent path.\"\"\"\n",
    "        result = grep(\"test\", \"nonexistent_dir\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"exist\" in data[\"error\"].lower()\n",
    "\n",
    "\n",
    "class TestSearchReplace:\n",
    "    \"\"\"Test search_replace function.\"\"\"\n",
    "    \n",
    "    def test_search_replace_success(self):\n",
    "        \"\"\"Test successful search and replace.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(\"Hello World\\nThis is a test\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            content = \"\"\"<<<<<<< SEARCH\n",
    "Hello World\n",
    "=======\n",
    "Hello Universe\n",
    ">>>>>>> REPLACE\"\"\"\n",
    "            \n",
    "            result = search_replace(temp_path, content)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"blocks_applied\"] == 1\n",
    "            assert data[\"lines_changed\"] == 0  # Same number of lines\n",
    "            \n",
    "            # Verify content was changed\n",
    "            with open(temp_path, 'r') as f:\n",
    "                new_content = f.read()\n",
    "            assert \"Hello Universe\" in new_content\n",
    "            assert \"Hello World\" not in new_content\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_search_replace_multiple_blocks(self):\n",
    "        \"\"\"Test search and replace with multiple blocks.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(\"Hello World\\nThis is a test\\nHello Again\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            content = \"\"\"<<<<<<< SEARCH\n",
    "Hello World\n",
    "=======\n",
    "Hello Universe\n",
    ">>>>>>> REPLACE\n",
    "\n",
    "<<<<<<< SEARCH\n",
    "Hello Again\n",
    "=======\n",
    "Hello Galaxy\n",
    ">>>>>>> REPLACE\"\"\"\n",
    "            \n",
    "            result = search_replace(temp_path, content)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is True\n",
    "            assert data[\"blocks_applied\"] == 2\n",
    "            \n",
    "            # Verify both changes were made\n",
    "            with open(temp_path, 'r') as f:\n",
    "                new_content = f.read()\n",
    "            assert \"Hello Universe\" in new_content\n",
    "            assert \"Hello Galaxy\" in new_content\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_search_replace_not_found(self):\n",
    "        \"\"\"Test search and replace when text not found.\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as f:\n",
    "            f.write(\"Hello World\")\n",
    "            temp_path = f.name\n",
    "        \n",
    "        try:\n",
    "            content = \"\"\"<<<<<<< SEARCH\n",
    "Goodbye World\n",
    "=======\n",
    "Hello Universe\n",
    ">>>>>>> REPLACE\"\"\"\n",
    "            \n",
    "            result = search_replace(temp_path, content)\n",
    "            data = json.loads(result)\n",
    "            \n",
    "            assert data[\"success\"] is False\n",
    "            assert \"not found\" in data[\"error\"].lower()\n",
    "        finally:\n",
    "            os.unlink(temp_path)\n",
    "    \n",
    "    def test_search_replace_empty_file_path(self):\n",
    "        \"\"\"Test search and replace with empty file path.\"\"\"\n",
    "        content = \"\"\"<<<<<<< SEARCH\n",
    "Hello\n",
    "=======\n",
    "Goodbye\n",
    ">>>>>>> REPLACE\"\"\"\n",
    "        \n",
    "        result = search_replace(\"\", content)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"empty\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_search_replace_empty_content(self):\n",
    "        \"\"\"Test search and replace with empty content.\"\"\"\n",
    "        result = search_replace(\"test.txt\", \"\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"empty\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_search_replace_file_not_found(self):\n",
    "        \"\"\"Test search and replace with non-existent file.\"\"\"\n",
    "        content = \"\"\"<<<<<<< SEARCH\n",
    "Hello\n",
    "=======\n",
    "Goodbye\n",
    ">>>>>>> REPLACE\"\"\"\n",
    "        \n",
    "        result = search_replace(\"nonexistent.txt\", content)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"exist\" in data[\"error\"].lower()\n",
    "    \n",
    "    def test_search_replace_invalid_format(self):\n",
    "        \"\"\"Test search and replace with invalid format.\"\"\"\n",
    "        # First create the file\n",
    "        with open(\"test.txt\", \"w\") as f:\n",
    "            f.write(\"some content\")\n",
    "        \n",
    "        result = search_replace(\"test.txt\", \"Just some text without proper format\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"format\" in data[\"error\"].lower() or \"block\" in data[\"error\"].lower()\n",
    "        \n",
    "        # Clean up\n",
    "        os.unlink(\"test.txt\")\n",
    "\n",
    "\n",
    "testReadFile = TestReadFile()\n",
    "testReadFile.test_read_file_success()\n",
    "testReadFile.test_read_file_with_offset()\n",
    "testReadFile.test_read_file_with_limit()\n",
    "testReadFile.test_read_file_empty_path()\n",
    "testReadFile.test_read_file_not_found()\n",
    "testReadFile.test_read_file_is_directory()\n",
    "testReadFile.test_read_file_negative_offset()\n",
    "testReadFile.test_read_file_invalid_limit()\n",
    "\n",
    "testWriteFile = TestWriteFile()\n",
    "testWriteFile.test_write_file_success()\n",
    "testWriteFile.test_write_file_overwrite()\n",
    "testWriteFile.test_write_file_no_overwrite()\n",
    "testWriteFile.test_write_file_empty_path()\n",
    "testWriteFile.test_write_file_empty_content()\n",
    "testWriteFile.test_write_file_too_large()\n",
    "testWriteFile.test_write_file_outside_project()\n",
    "\n",
    "testGrep = TestGrep()\n",
    "testGrep.test_grep_success()\n",
    "testGrep.test_grep_no_matches()\n",
    "testGrep.test_grep_with_max_matches()\n",
    "testGrep.test_grep_empty_pattern()\n",
    "testGrep.test_grep_path_not_found()\n",
    "\n",
    "testSearchReplace = TestSearchReplace()\n",
    "testSearchReplace.test_search_replace_success()\n",
    "testSearchReplace.test_search_replace_multiple_blocks()\n",
    "testSearchReplace.test_search_replace_not_found()\n",
    "testSearchReplace.test_search_replace_empty_file_path()\n",
    "testSearchReplace.test_search_replace_empty_content()\n",
    "testSearchReplace.test_search_replace_file_not_found()\n",
    "testSearchReplace.test_search_replace_invalid_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b470d8-fae2-4e1f-8b4c-156392e3fc9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:58:59.553357Z",
     "iopub.status.busy": "2026-02-03T23:58:59.553281Z",
     "iopub.status.idle": "2026-02-03T23:58:59.555810Z",
     "shell.execute_reply": "2026-02-03T23:58:59.555513Z",
     "shell.execute_reply.started": "2026-02-03T23:58:59.553351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"success\": false, \"error\": \"Error reading file nonexistent_file.txt: [Errno 2] No such file or directory. Please check the file path and your permissions.\"}'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_file(\"nonexistent_file.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1c801f-060a-425d-9b69-321acc238f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-03T23:59:56.142830Z",
     "iopub.status.busy": "2026-02-03T23:59:56.142737Z",
     "iopub.status.idle": "2026-02-03T23:59:56.185807Z",
     "shell.execute_reply": "2026-02-03T23:59:56.185227Z",
     "shell.execute_reply.started": "2026-02-03T23:59:56.142823Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnonexistent_file.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpanduser\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/pathlib.py:1240\u001b[39m, in \u001b[36mPath.resolve\u001b[39m\u001b[34m(self, strict)\u001b[39m\n\u001b[32m   1237\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mSymlink loop from \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % e.filename)\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1240\u001b[39m     s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flavour\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1242\u001b[39m     check_eloop(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/posixpath.py:428\u001b[39m, in \u001b[36mrealpath\u001b[39m\u001b[34m(filename, strict)\u001b[39m\n\u001b[32m    426\u001b[39m filename = os.fspath(filename)\n\u001b[32m    427\u001b[39m path, ok = _joinrealpath(filename[:\u001b[32m0\u001b[39m], filename, strict, {})\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/home/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/posixpath.py:415\u001b[39m, in \u001b[36mabspath\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    413\u001b[39m         cwd = os.getcwdb()\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m         cwd = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m     path = join(cwd, path)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m normpath(path)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "Path(\"nonexistent_file.txt\").expanduser().resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc9c99-373f-4ae9-8951-0e0fbe91e458",
   "metadata": {},
   "source": [
    "### Bash tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaf7d9e-3438-478d-a7a2-4f973b6a19f5",
   "metadata": {},
   "source": [
    "This tool provides a simple interface for running bash commands with comprehensive error handling and JSON output suitable for LLMs.\n",
    "\n",
    "Usage:\n",
    "\n",
    "```python\n",
    "import json\n",
    "from bash_simple import bash\n",
    "\n",
    "result = bash(\"ls -la\")\n",
    "data = json.loads(result)\n",
    "if data[\"success\"]:\n",
    "    print(data[\"stdout\"])\n",
    "else:\n",
    "    print(f\"Error: {data['error']}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d97c874f-db9a-4b83-9e2e-6e0382ff38c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-31T22:33:43.655388Z",
     "iopub.status.busy": "2026-01-31T22:33:43.655215Z",
     "iopub.status.idle": "2026-01-31T22:33:43.664359Z",
     "shell.execute_reply": "2026-01-31T22:33:43.663874Z",
     "shell.execute_reply.started": "2026-01-31T22:33:43.655377Z"
    }
   },
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "def _get_subprocess_encoding() -> str:\n",
    "    \"\"\"Get the appropriate encoding for subprocess communication.\"\"\"\n",
    "    if sys.platform == \"win32\":\n",
    "        # Windows console uses OEM code page (e.g., cp850, cp1252)\n",
    "        import ctypes\n",
    "\n",
    "        return f\"cp{ctypes.windll.kernel32.GetOEMCP()}\"\n",
    "    return \"utf-8\"\n",
    "\n",
    "\n",
    "def _get_base_env() -> dict[str, str]:\n",
    "    \"\"\"Get base environment for subprocess with safety settings.\"\"\"\n",
    "    base_env = {\n",
    "        **os.environ,\n",
    "        \"CI\": \"true\",\n",
    "        \"NONINTERACTIVE\": \"1\",\n",
    "        \"NO_TTY\": \"1\",\n",
    "        \"NO_COLOR\": \"1\",\n",
    "    }\n",
    "\n",
    "    if sys.platform == \"win32\":\n",
    "        base_env[\"GIT_PAGER\"] = \"more\"\n",
    "        base_env[\"PAGER\"] = \"more\"\n",
    "    else:\n",
    "        base_env[\"TERM\"] = \"dumb\"\n",
    "        base_env[\"DEBIAN_FRONTEND\"] = \"noninteractive\"\n",
    "        base_env[\"GIT_PAGER\"] = \"cat\"\n",
    "        base_env[\"PAGER\"] = \"cat\"\n",
    "        base_env[\"LESS\"] = \"-FX\"\n",
    "        base_env[\"LC_ALL\"] = \"en_US.UTF-8\"\n",
    "\n",
    "    return base_env\n",
    "\n",
    "\n",
    "def _get_default_allowlist() -> list[str]:\n",
    "    \"\"\"Get default list of allowed command prefixes.\"\"\"\n",
    "    common = [\"echo\", \"find\", \"git diff\", \"git log\", \"git status\", \"tree\", \"whoami\"]\n",
    "\n",
    "    if sys.platform == \"win32\":\n",
    "        return common + [\"dir\", \"findstr\", \"more\", \"type\", \"ver\", \"where\"]\n",
    "    else:\n",
    "        return common + [\n",
    "            \"cat\",\n",
    "            \"file\",\n",
    "            \"head\",\n",
    "            \"ls\",\n",
    "            \"pwd\",\n",
    "            \"stat\",\n",
    "            \"tail\",\n",
    "            \"uname\",\n",
    "            \"wc\",\n",
    "            \"which\",\n",
    "        ]\n",
    "\n",
    "\n",
    "def _get_default_denylist() -> list[str]:\n",
    "    \"\"\"Get default list of denied command prefixes.\"\"\"\n",
    "    common = [\"gdb\", \"pdb\", \"passwd\"]\n",
    "\n",
    "    if sys.platform == \"win32\":\n",
    "        return common + [\"cmd /k\", \"powershell -NoExit\", \"pwsh -NoExit\", \"notepad\"]\n",
    "    else:\n",
    "        return common + [\n",
    "            \"nano\",\n",
    "            \"vim\",\n",
    "            \"vi\",\n",
    "            \"emacs\",\n",
    "            \"bash -i\",\n",
    "            \"sh -i\",\n",
    "            \"zsh -i\",\n",
    "            \"fish -i\",\n",
    "            \"dash -i\",\n",
    "            \"screen\",\n",
    "            \"tmux\",\n",
    "        ]\n",
    "\n",
    "\n",
    "def _get_default_denylist_standalone() -> list[str]:\n",
    "    \"\"\"Get default list of commands denied when run without arguments.\"\"\"\n",
    "    common = [\"python\", \"python3\", \"ipython\"]\n",
    "\n",
    "    if sys.platform == \"win32\":\n",
    "        return common + [\"cmd\", \"powershell\", \"pwsh\", \"notepad\"]\n",
    "    else:\n",
    "        return common + [\n",
    "            \"bash\",\n",
    "            \"sh\",\n",
    "            \"nohup\",\n",
    "            \"vi\",\n",
    "            \"vim\",\n",
    "            \"emacs\",\n",
    "            \"nano\",\n",
    "            \"su\",\n",
    "        ]\n",
    "\n",
    "\n",
    "def _is_denylisted(command: str, denylist: list[str]) -> bool:\n",
    "    \"\"\"Check if a command is in the denylist.\"\"\"\n",
    "    return any(command.startswith(pattern) for pattern in denylist)\n",
    "\n",
    "\n",
    "def _is_standalone_denylisted(command: str, denylist_standalone: list[str]) -> bool:\n",
    "    \"\"\"Check if a command is in the standalone denylist.\"\"\"\n",
    "    parts = command.split()\n",
    "    if not parts:\n",
    "        return False\n",
    "\n",
    "    base_command = parts[0]\n",
    "    has_args = len(parts) > 1\n",
    "\n",
    "    if not has_args:\n",
    "        command_name = os.path.basename(base_command)\n",
    "        if command_name in denylist_standalone:\n",
    "            return True\n",
    "        if base_command in denylist_standalone:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def _is_allowlisted(command: str, allowlist: list[str]) -> bool:\n",
    "    \"\"\"Check if a command is in the allowlist.\"\"\"\n",
    "    return any(command.startswith(pattern) for pattern in allowlist)\n",
    "\n",
    "\n",
    "def _check_command_safety(\n",
    "    command: str,\n",
    "    allowlist: list[str] | None = None,\n",
    "    denylist: list[str] | None = None,\n",
    "    denylist_standalone: list[str] | None = None,\n",
    ") -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Check if a command is safe to run.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each command runs independently in a fresh environment\n",
    "    - **Timeout**: Controls how long the command can run before being killed\n",
    "    - When timeout is not specified (or set to None), the config default is used\n",
    "    - If a command is timing out, increase the timeout using the timeout argument\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use for quick system checks and git operations\n",
    "    - Prefer dedicated tools over bash commands when available\n",
    "    - Use specific, focused commands for better results\n",
    "    - Limit output with tools like head/tail when dealing with large files\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If command fails, check the return code and stderr\n",
    "    - If command times out, increase the timeout parameter\n",
    "    - If command is denied, use an allowed command or request user confirmation\n",
    "    - If command is unsafe, use a safer alternative\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (is_safe, error_message)\n",
    "    \"\"\"\n",
    "    if allowlist is None:\n",
    "        allowlist = _get_default_allowlist()\n",
    "    if denylist is None:\n",
    "        denylist = _get_default_denylist()\n",
    "    if denylist_standalone is None:\n",
    "        denylist_standalone = _get_default_denylist_standalone()\n",
    "\n",
    "    # Extract command parts (simplified version)\n",
    "    # For safety checks, we just check the full command string\n",
    "    full_command = command.strip()\n",
    "\n",
    "    if not full_command:\n",
    "        return False, \"Command cannot be empty\"\n",
    "\n",
    "    # Check denylist\n",
    "    if _is_denylisted(full_command, denylist):\n",
    "        return False, f\"Command is denied: {full_command}\"\n",
    "\n",
    "    # Check standalone denylist\n",
    "    if _is_standalone_denylisted(full_command, denylist_standalone):\n",
    "        return False, f\"Command is denied when run without arguments: {full_command}\"\n",
    "\n",
    "    # Check allowlist\n",
    "    if _is_allowlisted(full_command, allowlist):\n",
    "        return True, \"\"\n",
    "\n",
    "    # If not explicitly allowed, ask for user confirmation\n",
    "    # This matches the Mistral Vibe behavior where unknown commands\n",
    "    # require user confirmation\n",
    "    response = input(f\"\\n⚠️  Warning: About to execute command '{full_command}'.\\nDo you want to proceed? (yes/no): \").strip().lower()\n",
    "    if response not in ['yes', 'y']:\n",
    "        return False, f\"Command '{full_command}' was cancelled by user.\"\n",
    "    \n",
    "    return True, \"\"\n",
    "\n",
    "def bash(\n",
    "    command: str,\n",
    "    timeout: int = 300,\n",
    "    max_output_bytes: int = 16000,\n",
    "    allowlist: list[str] | None = None,\n",
    "    denylist: list[str] | None = None,\n",
    "    denylist_standalone: list[str] | None = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Run a bash command and return result as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each command runs independently in a fresh environment\n",
    "    - **Timeout**: Controls how long the command can run before being killed\n",
    "    - When timeout is not specified (or set to None), the config default is used\n",
    "    - If a command is timing out, increase the timeout using the timeout argument\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use for quick system checks and git operations\n",
    "    - Prefer dedicated tools over bash commands when available\n",
    "    - Use specific, focused commands for better results\n",
    "    - Limit output with tools like head/tail when dealing with large files\n",
    "    \n",
    "    **IMPORTANT: Use dedicated tools if available instead of these bash commands:**\n",
    "    \n",
    "    **File Operations - DO NOT USE:**\n",
    "    - `cat filename` → Use `read_file(path=\"filename\")`\n",
    "    - `head -n 20 filename` → Use `read_file(path=\"filename\", limit=20)`\n",
    "    - `tail -n 20 filename` → Read with offset: `read_file(path=\"filename\", offset=<line_number>, limit=20)`\n",
    "    - `sed -n '100,200p' filename` → Use `read_file(path=\"filename\", offset=99, limit=101)`\n",
    "    - `less`, `more`, `vim`, `nano` → Use `read_file` with offset/limit for navigation\n",
    "    - `echo \"content\" > file` → Use `write_file(path=\"file\", content=\"content\")`\n",
    "    - `echo \"content\" >> file` → Read first, then `write_file` with overwrite=true\n",
    "    \n",
    "    **Search Operations - DO NOT USE:**\n",
    "    - `grep -r \"pattern\" .` → Use `grep(pattern=\"pattern\", path=\".\")`\n",
    "    - `find . -name \"*.py\"` → Use `bash(\"ls -la\")` for current dir or `grep` with appropriate pattern\n",
    "    - `ag`, `ack`, `rg` commands → Use the `grep` tool\n",
    "    - `locate` → Use `grep` tool\n",
    "    \n",
    "    **File Modification - DO NOT USE:**\n",
    "    - `sed -i 's/old/new/g' file` → Use `search_replace` tool\n",
    "    - `awk` for file editing → Use `search_replace` tool\n",
    "    - Any in-place file editing → Use `search_replace` tool\n",
    "    \n",
    "    **APPROPRIATE bash uses:**\n",
    "    - System information: `pwd`, `whoami`, `date`, `uname -a`\n",
    "    - Directory listings: `ls -la`, `tree` (if available)\n",
    "    - Git operations: `git status`, `git log --oneline -10`, `git diff`\n",
    "    - Process info: `ps aux | grep process`, `top -n 1`\n",
    "    - Network checks: `ping -c 1 google.com`, `curl -I https://example.com`\n",
    "    - Package management: `pip list`, `npm list`\n",
    "    - Environment checks: `env | grep VAR`, `which python`\n",
    "    - File metadata: `stat filename`, `file filename`, `wc -l filename`\n",
    "    \n",
    "    Args:\n",
    "        command: The bash command to run\n",
    "        timeout: Maximum execution time in seconds (default: 300)\n",
    "        max_output_bytes: Maximum bytes to capture from stdout and stderr (default: 16000)\n",
    "        allowlist: Command prefixes that are automatically allowed\n",
    "        denylist: Command prefixes that are automatically denied\n",
    "        denylist_standalone: Commands that are denied only when run without arguments\n",
    "    \n",
    "    Returns:\n",
    "        JSON string with:\n",
    "        - success: bool indicating if command succeeded\n",
    "        - command: the command that was run\n",
    "        - stdout: captured stdout (truncated if too large)\n",
    "        - stderr: captured stderr (truncated if too large)\n",
    "        - returncode: process return code\n",
    "        - error: error message if command failed (None if success)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate command safety\n",
    "        is_safe, safety_error = _check_command_safety(\n",
    "            command, allowlist, denylist, denylist_standalone\n",
    "        )\n",
    "        if not is_safe:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"command\": command,\n",
    "                \"stdout\": \"\",\n",
    "                \"stderr\": \"\",\n",
    "                \"returncode\": -1,\n",
    "                \"error\": safety_error,\n",
    "            })\n",
    "\n",
    "        # Run the command\n",
    "        encoding = _get_subprocess_encoding()\n",
    "        env = _get_base_env()\n",
    "\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                shell=True,\n",
    "                check=False,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE,\n",
    "                stdin=subprocess.DEVNULL,\n",
    "                timeout=timeout,\n",
    "                env=env,\n",
    "            )\n",
    "        except subprocess.TimeoutExpired:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"command\": command,\n",
    "                \"stdout\": \"\",\n",
    "                \"stderr\": \"\",\n",
    "                \"returncode\": -1,\n",
    "                \"error\": f\"Command timed out after {timeout}s: {command!r}\",\n",
    "            })\n",
    "        except Exception as exc:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"command\": command,\n",
    "                \"stdout\": \"\",\n",
    "                \"stderr\": \"\",\n",
    "                \"returncode\": -1,\n",
    "                \"error\": f\"Error running command {command!r}: {str(exc)}\",\n",
    "            })\n",
    "\n",
    "        # Decode and truncate output\n",
    "        stdout = result.stdout.decode(encoding, errors=\"replace\")[:max_output_bytes]\n",
    "        stderr = result.stderr.decode(encoding, errors=\"replace\")[:max_output_bytes]\n",
    "\n",
    "        returncode = result.returncode\n",
    "\n",
    "        # Check if command failed\n",
    "        if returncode != 0:\n",
    "            error_msg = f\"Command failed: {command!r}\\n\"\n",
    "            error_msg += f\"Return code: {returncode}\"\n",
    "            if stderr:\n",
    "                error_msg += f\"\\nStderr: {stderr}\"\n",
    "            if stdout:\n",
    "                error_msg += f\"\\nStdout: {stdout}\"\n",
    "\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"command\": command,\n",
    "                \"stdout\": stdout,\n",
    "                \"stderr\": stderr,\n",
    "                \"returncode\": returncode,\n",
    "                \"error\": error_msg.strip(),\n",
    "            })\n",
    "\n",
    "        # Success\n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"command\": command,\n",
    "            \"stdout\": stdout,\n",
    "            \"stderr\": stderr,\n",
    "            \"returncode\": returncode,\n",
    "            \"error\": None,\n",
    "        })\n",
    "\n",
    "    except Exception as exc:\n",
    "        return json.dumps({\n",
    "            \"success\": False,\n",
    "            \"command\": command,\n",
    "            \"stdout\": \"\",\n",
    "            \"stderr\": \"\",\n",
    "            \"returncode\": -1,\n",
    "            \"error\": f\"Unexpected error: {str(exc)}\",\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d3e26-4de1-46d7-bda3-cb9771828f50",
   "metadata": {},
   "source": [
    "Comprehensive tests for bash_simple.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c26634-7f0d-4a52-a431-a2f2e83b9e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import Mock, patch\n",
    "\n",
    "class TestBashSimple:\n",
    "    \"\"\"Test suite for bash_simple tool\"\"\"\n",
    "\n",
    "    def test_bash_success(self):\n",
    "        \"\"\"Test successful command execution\"\"\"\n",
    "        result = bash(\"echo 'Hello World'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert data[\"command\"] == \"echo 'Hello World'\"\n",
    "        assert \"Hello World\" in data[\"stdout\"]\n",
    "        assert data[\"stderr\"] == \"\"\n",
    "        assert data[\"returncode\"] == 0\n",
    "        assert data[\"error\"] is None\n",
    "\n",
    "    def test_bash_failure(self):\n",
    "        \"\"\"Test failed command execution\"\"\"\n",
    "        result = bash(\"exit 1\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"command\"] == \"exit 1\"\n",
    "        assert data[\"returncode\"] == 1\n",
    "        assert data[\"error\"] is not None\n",
    "        assert \"Command failed\" in data[\"error\"]\n",
    "\n",
    "    def test_bash_timeout(self):\n",
    "        \"\"\"Test command timeout\"\"\"\n",
    "        result = bash(\"sleep 10\", timeout=1)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"error\"] is not None\n",
    "        assert \"timed out\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_denylisted_command(self):\n",
    "        \"\"\"Test denylisted command\"\"\"\n",
    "        result = bash(\"vim\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"error\"] is not None\n",
    "        assert \"denied\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_denylisted_standalone(self):\n",
    "        \"\"\"Test standalone denylisted command\"\"\"\n",
    "        result = bash(\"python\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"error\"] is not None\n",
    "        assert \"denied\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_allowlisted_command(self):\n",
    "        \"\"\"Test allowlisted command\"\"\"\n",
    "        result = bash(\"echo 'test'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"test\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_custom_allowlist(self):\n",
    "        \"\"\"Test custom allowlist\"\"\"\n",
    "        result = bash(\"echo 'test'\", allowlist=[\"echo\"])\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"test\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_custom_denylist(self):\n",
    "        \"\"\"Test custom denylist\"\"\"\n",
    "        result = bash(\"echo 'test'\", denylist=[\"echo\"])\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"denied\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_output_truncation(self):\n",
    "        \"\"\"Test output truncation\"\"\"\n",
    "        # Create a large output\n",
    "        result = bash(\"for i in {1..1000}; do echo 'test line $i'; done\", max_output_bytes=100)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        # Output should be truncated\n",
    "        assert len(data[\"stdout\"]) <= 100\n",
    "\n",
    "    def test_bash_empty_command(self):\n",
    "        \"\"\"Test empty command\"\"\"\n",
    "        result = bash(\"\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"error\"] is not None\n",
    "\n",
    "    def test_bash_invalid_command(self):\n",
    "        \"\"\"Test invalid command\"\"\"\n",
    "        result = bash(\"nonexistent_command_xyz123\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"returncode\"] != 0\n",
    "\n",
    "    def test_bash_stderr_capture(self):\n",
    "        \"\"\"Test stderr capture\"\"\"\n",
    "        result = bash(\"echo 'stdout' >&2\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Should capture stderr\n",
    "        assert data[\"stderr\"] != \"\"\n",
    "\n",
    "    def test_bash_json_format(self):\n",
    "        \"\"\"Test JSON format consistency\"\"\"\n",
    "        result = bash(\"echo 'test'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Check all required fields are present\n",
    "        assert \"success\" in data\n",
    "        assert \"command\" in data\n",
    "        assert \"stdout\" in data\n",
    "        assert \"stderr\" in data\n",
    "        assert \"returncode\" in data\n",
    "        assert \"error\" in data\n",
    "\n",
    "    def test_bash_custom_timeout(self):\n",
    "        \"\"\"Test custom timeout\"\"\"\n",
    "        result = bash(\"sleep 5\", timeout=1)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"timed out\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_allowlist_with_args(self):\n",
    "        \"\"\"Test allowlist with commands that have arguments\"\"\"\n",
    "        result = bash(\"echo 'hello world'\", allowlist=[\"echo\"])\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"hello world\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_denylist_with_args(self):\n",
    "        \"\"\"Test denylist with commands that have arguments\"\"\"\n",
    "        result = bash(\"vim file.txt\", denylist=[\"vim\"])\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"denied\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_standalone_denylist_with_args(self):\n",
    "        \"\"\"Test standalone denylist with arguments\"\"\"\n",
    "        result = bash(\"python -c 'print(1)'\", denylist_standalone=[\"python\"])\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Should succeed because it has arguments\n",
    "        assert data[\"success\"] is True\n",
    "\n",
    "    def test_bash_standalone_denylist_without_args(self):\n",
    "        \"\"\"Test standalone denylist without arguments\"\"\"\n",
    "        result = bash(\"python\", denylist_standalone=[\"python\"])\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Should fail because it has no arguments\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"denied\" in data[\"error\"].lower()\n",
    "\n",
    "    def test_bash_special_chars(self):\n",
    "        \"\"\"Test command with special characters\"\"\"\n",
    "        result = bash(\"echo 'test with spaces and quotes'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"test with spaces and quotes\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_pipe_command(self):\n",
    "        \"\"\"Test piped commands\"\"\"\n",
    "        result = bash(\"echo 'hello' | tr 'a-z' 'A-Z'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"HELLO\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_redirect_command(self):\n",
    "        \"\"\"Test command with redirection\"\"\"\n",
    "        result = bash(\"echo 'test' > /tmp/test_bash_redirect.txt && cat /tmp/test_bash_redirect.txt\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"test\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_environment_variables(self):\n",
    "        \"\"\"Test environment variable handling\"\"\"\n",
    "        result = bash(\"echo $CI\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"true\" in data[\"stdout\"].lower()\n",
    "\n",
    "    def test_bash_safe_environment(self):\n",
    "        \"\"\"Test that safe environment variables are set\"\"\"\n",
    "        result = bash(\"echo $TERM\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"dumb\" in data[\"stdout\"].lower()\n",
    "\n",
    "    def test_bash_unicode_output(self):\n",
    "        \"\"\"Test unicode output handling\"\"\"\n",
    "        result = bash(\"echo 'Hello 世界'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"世界\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_error_message_details(self):\n",
    "        \"\"\"Test that error messages contain useful details\"\"\"\n",
    "        result = bash(\"ls /nonexistent_directory\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"error\"] is not None\n",
    "        assert \"Command failed\" in data[\"error\"]\n",
    "        assert str(data[\"returncode\"]) in data[\"error\"]\n",
    "\n",
    "    def test_bash_large_output(self):\n",
    "        \"\"\"Test handling of large output\"\"\"\n",
    "        result = bash(\"for i in {1..100}; do echo 'line $i with some text'; done\", max_output_bytes=500)\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"stdout\"]) <= 500\n",
    "\n",
    "    def test_bash_returncode_zero_success(self):\n",
    "        \"\"\"Test that returncode 0 indicates success\"\"\"\n",
    "        result = bash(\"true\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert data[\"returncode\"] == 0\n",
    "\n",
    "    def test_bash_returncode_nonzero_failure(self):\n",
    "        \"\"\"Test that non-zero returncode indicates failure\"\"\"\n",
    "        result = bash(\"false\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert data[\"returncode\"] != 0\n",
    "\n",
    "    def test_bash_multiple_commands(self):\n",
    "        \"\"\"Test multiple commands separated by ;\"\"\"\n",
    "        result = bash(\"echo 'first'; echo 'second'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"first\" in data[\"stdout\"]\n",
    "        assert \"second\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_command_with_quotes(self):\n",
    "        \"\"\"Test command with various quote styles\"\"\"\n",
    "        result = bash(\"echo 'quoted' && echo 'double quoted'\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "\n",
    "    def test_bash_shell_features(self):\n",
    "        \"\"\"Test shell features like variables and expansions\"\"\"\n",
    "        result = bash(\"x=5; y=10; echo $((x + y))\")\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert \"15\" in data[\"stdout\"]\n",
    "\n",
    "    def test_bash_safety_checks(self):\n",
    "        \"\"\"Test comprehensive safety checks\"\"\"\n",
    "        # Test that denylisted commands are blocked\n",
    "        denylisted_commands = [\n",
    "            \"vim\",\n",
    "            \"nano\",\n",
    "            \"emacs\",\n",
    "            \"bash -i\",\n",
    "        ]\n",
    "        \n",
    "        for cmd in denylisted_commands:\n",
    "            result = bash(cmd)\n",
    "            data = json.loads(result)\n",
    "            # These should be blocked by denylist\n",
    "            assert data[\"success\"] is False\n",
    "            assert \"denied\" in data[\"error\"].lower()\n",
    "        \n",
    "        # Test that standalone denylisted commands without args are blocked\n",
    "        result = bash(\"python\")\n",
    "        data = json.loads(result)\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"denied\" in data[\"error\"].lower()\n",
    "\n",
    "\n",
    "# Run all tests and report results\n",
    "test_class = TestBashSimple()\n",
    "tests = [method for method in dir(test_class) if method.startswith(\"test_\")]\n",
    "\n",
    "passed = 0\n",
    "failed = 0\n",
    "for test_name in tests:\n",
    "    try:\n",
    "        getattr(test_class, test_name)()\n",
    "        print(f\"✓ {test_name}\")\n",
    "        passed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {test_name}: {e}\")\n",
    "        failed += 1\n",
    "\n",
    "print(f\"\\n{passed}/{len(tests)} tests passed\")\n",
    "return failed == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb3515a-5195-417b-8ae2-8f7e3e729922",
   "metadata": {},
   "source": [
    "### Todo tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb995c-d5e6-41ce-b49a-2ac69d3f59b9",
   "metadata": {},
   "source": [
    "This tool provides a simple interface for managing todos with read and write operations.\n",
    "\n",
    "All functions return JSON strings that can be easily parsed by LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b68cb-20e8-4a7c-bf34-df813ba9b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "class TodoStatus(StrEnum):\n",
    "    \"\"\"Status of a todo item.\"\"\"\n",
    "    PENDING = \"PENDING\"\n",
    "    IN_PROGRESS = \"IN_PROGRESS\"\n",
    "    COMPLETED = \"COMPLETED\"\n",
    "    CANCELLED = \"CANCELLED\"\n",
    "\n",
    "\n",
    "class TodoPriority(StrEnum):\n",
    "    \"\"\"Priority of a todo item.\"\"\"\n",
    "    LOW = \"LOW\"\n",
    "    MEDIUM = \"MEDIUM\"\n",
    "    HIGH = \"HIGH\"\n",
    "\n",
    "\n",
    "class TodoItem:\n",
    "    \"\"\"A todo item with id, content, status, and priority.\"\"\"\n",
    "    \n",
    "    def __init__(self, id: str, content: str, status: TodoStatus = TodoStatus.PENDING, priority: TodoPriority = TodoPriority.MEDIUM):\n",
    "        self.id = id\n",
    "        self.content = content\n",
    "        self.status = status\n",
    "        self.priority = priority\n",
    "    \n",
    "    def to_dict(self) -> dict[str, Any]:\n",
    "        \"\"\"Convert todo item to dictionary.\"\"\"\n",
    "        return {\n",
    "            \"id\": self.id,\n",
    "            \"content\": self.content,\n",
    "            \"status\": self.status.value,\n",
    "            \"priority\": self.priority.value,\n",
    "        }\n",
    "\n",
    "\n",
    "class TodoSimple:\n",
    "    \"\"\"Simple synchronous todo manager.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize todo manager with empty state.\"\"\"\n",
    "        self._todos: list[TodoItem] = []\n",
    "    \n",
    "    def read_todos(self) -> str:\n",
    "        \"\"\"Read all todos.\n",
    "        \n",
    "        **Key characteristics:**\n",
    "        - **Stateless**: Each read operation is independent\n",
    "        - **Simple interface**: Returns all todos in a single call\n",
    "        \n",
    "        **Usage Tips:**\n",
    "        - Use this to view the current state of all todos\n",
    "        - Call this before making changes to understand the current state\n",
    "        - Use the returned todos to plan your next actions\n",
    "        \n",
    "        **Error Handling:**\n",
    "        - If you get an error, check if the todo data is corrupted\n",
    "        - If todos are empty, start by adding new todos\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with success status and todos list\n",
    "        \n",
    "        Example:\n",
    "            {\n",
    "                \"success\": true,\n",
    "                \"message\": \"Retrieved 3 todos\",\n",
    "                \"todos\": [\n",
    "                    {\"id\": \"1\", \"content\": \"Task 1\", \"status\": \"PENDING\", \"priority\": \"MEDIUM\"}\n",
    "                ],\n",
    "                \"total_count\": 3\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            todos_dict = [todo.to_dict() for todo in self._todos]\n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"message\": f\"Retrieved {len(self._todos)} todos\",\n",
    "                \"todos\": todos_dict,\n",
    "                \"total_count\": len(self._todos),\n",
    "            }, indent=2)\n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to read todos: {str(e)}\",\n",
    "            }, indent=2)\n",
    "    \n",
    "    def write_todos(self, todos: list[dict[str, Any]] | None = None) -> str:\n",
    "        \"\"\"Write/update todos.\n",
    "        \n",
    "        **Key characteristics:**\n",
    "        - **Stateless**: Each write operation is independent\n",
    "        - **Complete replacement**: You must provide the ENTIRE list of todos\n",
    "        - **Clear all**: Pass None to clear all todos\n",
    "        \n",
    "        **Usage Tips:**\n",
    "        - Use this to update the complete todo list\n",
    "        - You must include ALL todos you want to keep (any not included will be removed)\n",
    "        - Use read_todos() first to get the current state\n",
    "        - When adding new todos, include all existing ones plus the new ones\n",
    "        - When removing todos, exclude them from the list\n",
    "        \n",
    "        **Error Handling:**\n",
    "        - If todo format is invalid, check the id and content fields\n",
    "        - If status or priority is invalid, use valid values (PENDING/IN_PROGRESS/COMPLETED/CANCELLED, LOW/MEDIUM/HIGH)\n",
    "        - If you get an error, read the todos first to understand the current state\n",
    "        \n",
    "        Args:\n",
    "            todos: List of todo dictionaries to write. If None, clears all todos.\n",
    "                   Each todo should have: id (str), content (str)\n",
    "                   Optional: status (str), priority (str)\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with success status and updated todos\n",
    "        \n",
    "        Example:\n",
    "            {\n",
    "                \"success\": true,\n",
    "                \"message\": \"Updated 2 todos\",\n",
    "                \"todos\": [\n",
    "                    {\"id\": \"1\", \"content\": \"Task 1\", \"status\": \"PENDING\", \"priority\": \"MEDIUM\"},\n",
    "                    {\"id\": \"2\", \"content\": \"Task 2\", \"status\": \"IN_PROGRESS\", \"priority\": \"HIGH\"}\n",
    "                ],\n",
    "                \"total_count\": 2\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate input\n",
    "            if todos is None:\n",
    "                self._todos = []\n",
    "                todos_dict = []\n",
    "                message = \"Cleared all todos\"\n",
    "            else:\n",
    "                if not isinstance(todos, list):\n",
    "                    return json.dumps({\n",
    "                        \"success\": False,\n",
    "                        \"error\": \"todos must be a list of dictionaries\",\n",
    "                    }, indent=2)\n",
    "                \n",
    "                if len(todos) > 100:\n",
    "                    return json.dumps({\n",
    "                        \"success\": False,\n",
    "                        \"error\": \"Cannot store more than 100 todos\",\n",
    "                    }, indent=2)\n",
    "                \n",
    "                # Convert dicts to TodoItem objects\n",
    "                todo_objects = []\n",
    "                ids = set()\n",
    "                \n",
    "                for todo_dict in todos:\n",
    "                    if not isinstance(todo_dict, dict):\n",
    "                        return json.dumps({\n",
    "                            \"success\": False,\n",
    "                            \"error\": \"Each todo must be a dictionary\",\n",
    "                        }, indent=2)\n",
    "                    \n",
    "                    if \"id\" not in todo_dict or \"content\" not in todo_dict:\n",
    "                        return json.dumps({\n",
    "                            \"success\": False,\n",
    "                            \"error\": \"id and 'content' fields are required\",\n",
    "                        }, indent=2)\n",
    "                    \n",
    "                    todo_id = todo_dict[\"id\"]\n",
    "                    if todo_id in ids:\n",
    "                        return json.dumps({\n",
    "                            \"success\": False,\n",
    "                            \"error\": f\"Duplicate todo ID: {todo_id}\",\n",
    "                        }, indent=2)\n",
    "                    ids.add(todo_id)\n",
    "                    \n",
    "                    # Parse status\n",
    "                    status = TodoStatus(todo_dict.get(\"status\", \"PENDING\"))\n",
    "                    \n",
    "                    # Parse priority\n",
    "                    priority = TodoPriority(todo_dict.get(\"priority\", \"MEDIUM\"))\n",
    "                    \n",
    "                    todo_obj = TodoItem(\n",
    "                        id=todo_id,\n",
    "                        content=todo_dict[\"content\"],\n",
    "                        status=status,\n",
    "                        priority=priority,\n",
    "                    )\n",
    "                    todo_objects.append(todo_obj)\n",
    "                \n",
    "                self._todos = todo_objects\n",
    "                todos_dict = [todo.to_dict() for todo in self._todos]\n",
    "                message = f\"Updated {len(self._todos)} todos\"\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"message\": message,\n",
    "                \"todos\": todos_dict,\n",
    "                \"total_count\": len(self._todos),\n",
    "            }, indent=2)\n",
    "        \n",
    "        except ValueError as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Invalid value: {str(e)}\",\n",
    "            }, indent=2)\n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to write todos: {str(e)}\",\n",
    "            }, indent=2)\n",
    "    \n",
    "    def add_todo(self, id: str, content: str, status: str = \"PENDING\", priority: str = \"MEDIUM\") -> str:\n",
    "        \"\"\"Add a single todo item.\n",
    "        \n",
    "        **Key characteristics:**\n",
    "        - **Stateless**: Each add operation is independent\n",
    "        - **Unique IDs**: Each todo must have a unique ID\n",
    "        \n",
    "        **Usage Tips:**\n",
    "        - Use this to add individual todos without managing the full list\n",
    "        - Use unique, descriptive IDs for each todo\n",
    "        - Use PENDING status for new todos\n",
    "        - Use HIGH priority for urgent tasks\n",
    "        - Use LOW priority for low-priority tasks\n",
    "        \n",
    "        **Error Handling:**\n",
    "        - If ID already exists, use a different ID\n",
    "        - If status is invalid, use valid values (PENDING, IN_PROGRESS, COMPLETED, CANCELLED)\n",
    "        - If priority is invalid, use valid values (LOW, MEDIUM, HIGH)\n",
    "        \n",
    "        Args:\n",
    "            id: Unique identifier for the todo\n",
    "            content: Description of the todo\n",
    "            status: Status of the todo (PENDING, IN_PROGRESS, COMPLETED, CANCELLED)\n",
    "            priority: Priority of the todo (LOW, MEDIUM, HIGH)\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with success status\n",
    "        \n",
    "        Example:\n",
    "            {\n",
    "                \"success\": true,\n",
    "                \"message\": \"Added todo with id '1'\",\n",
    "                \"todo\": {\"id\": \"1\", \"content\": \"Task 1\", \"status\": \"PENDING\", \"priority\": \"MEDIUM\"}\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check if id already exists\n",
    "            if any(todo.id == id for todo in self._todos):\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Todo with id '{id}' already exists\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            # Parse status\n",
    "            try:\n",
    "                status_enum = TodoStatus(status)\n",
    "            except ValueError:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Invalid status '{status}'. Use: PENDING, IN_PROGRESS, COMPLETED, CANCELLED\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            # Parse priority\n",
    "            try:\n",
    "                priority_enum = TodoPriority(priority)\n",
    "            except ValueError:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Invalid priority '{priority}'. Use: LOW, MEDIUM, HIGH\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            todo_item = TodoItem(id=id, content=content, status=status_enum, priority=priority_enum)\n",
    "            self._todos.append(todo_item)\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"message\": f\"Added todo with id '{id}'\",\n",
    "                \"todo\": todo_item.to_dict(),\n",
    "            }, indent=2)\n",
    "        \n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to add todo: {str(e)}\",\n",
    "            }, indent=2)\n",
    "    \n",
    "    def update_todo_status(self, id: str, status: str) -> str:\n",
    "        \"\"\"Update the status of a todo item.\n",
    "        \n",
    "        **Key characteristics:**\n",
    "        - **Stateless**: Each update operation is independent\n",
    "        - **Status management**: Only updates the status, not other fields\n",
    "        \n",
    "        **Usage Tips:**\n",
    "        - Use this to mark todos as IN_PROGRESS when starting work\n",
    "        - Use this to mark todos as COMPLETED when finished\n",
    "        - Use this to mark todos as CANCELLED when abandoned\n",
    "        - Use this to reset todos to PENDING when needed\n",
    "        \n",
    "        **Error Handling:**\n",
    "        - If todo not found, check the ID and add the todo first\n",
    "        - If status is invalid, use valid values (PENDING, IN_PROGRESS, COMPLETED, CANCELLED)\n",
    "        \n",
    "        Args:\n",
    "            id: ID of the todo to update\n",
    "            status: New status (PENDING, IN_PROGRESS, COMPLETED, CANCELLED)\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with success status\n",
    "        \n",
    "        Example:\n",
    "            {\n",
    "                \"success\": true,\n",
    "                \"message\": \"Updated status of todo '1' to COMPLETED\",\n",
    "                \"todo\": {\"id\": \"1\", \"content\": \"Task 1\", \"status\": \"COMPLETED\", \"priority\": \"MEDIUM\"}\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find the todo\n",
    "            todo = None\n",
    "            for t in self._todos:\n",
    "                if t.id == id:\n",
    "                    todo = t\n",
    "                    break\n",
    "            \n",
    "            if todo is None:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Todo with id '{id}' not found\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            # Parse status\n",
    "            try:\n",
    "                status_enum = TodoStatus(status)\n",
    "            except ValueError:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Invalid status '{status}'. Use: PENDING, IN_PROGRESS, COMPLETED, CANCELLED\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            todo.status = status_enum\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"message\": f\"Updated status of todo '{id}' to {status}\",\n",
    "                \"todo\": todo.to_dict(),\n",
    "            }, indent=2)\n",
    "        \n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to update todo status: {str(e)}\",\n",
    "            }, indent=2)\n",
    "    \n",
    "    def update_todo_priority(self, id: str, priority: str) -> str:\n",
    "        \"\"\"Update the priority of a todo item.\n",
    "        \n",
    "        **Key characteristics:**\n",
    "        - **Stateless**: Each update operation is independent\n",
    "        - **Priority management**: Only updates the priority, not other fields\n",
    "        \n",
    "        **Usage Tips:**\n",
    "        - Use this to increase priority for urgent tasks\n",
    "        - Use this to decrease priority for less urgent tasks\n",
    "        - Use HIGH priority for time-sensitive tasks\n",
    "        - Use LOW priority for tasks that can wait\n",
    "        - Use MEDIUM priority for normal tasks\n",
    "        \n",
    "        **Error Handling:**\n",
    "        - If todo not found, check the ID and add the todo first\n",
    "        - If priority is invalid, use valid values (LOW, MEDIUM, HIGH)\n",
    "        \n",
    "        Args:\n",
    "            id: ID of the todo to update\n",
    "            priority: New priority (LOW, MEDIUM, HIGH)\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with success status\n",
    "        \n",
    "        Example:\n",
    "            {\n",
    "                \"success\": true,\n",
    "                \"message\": \"Updated priority of todo '1' to HIGH\",\n",
    "                \"todo\": {\"id\": \"1\", \"content\": \"Task 1\", \"status\": \"PENDING\", \"priority\": \"HIGH\"}\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find the todo\n",
    "            todo = None\n",
    "            for t in self._todos:\n",
    "                if t.id == id:\n",
    "                    todo = t\n",
    "                    break\n",
    "            \n",
    "            if todo is None:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Todo with id '{id}' not found\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            # Parse priority\n",
    "            try:\n",
    "                priority_enum = TodoPriority(priority)\n",
    "            except ValueError:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Invalid priority '{priority}'. Use: LOW, MEDIUM, HIGH\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            todo.priority = priority_enum\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"message\": f\"Updated priority of todo '{id}' to {priority}\",\n",
    "                \"todo\": todo.to_dict(),\n",
    "            }, indent=2)\n",
    "        \n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to update todo priority: {str(e)}\",\n",
    "            }, indent=2)\n",
    "    \n",
    "    def delete_todo(self, id: str) -> str:\n",
    "        \"\"\"Delete a todo item.\n",
    "        \n",
    "        **Key characteristics:**\n",
    "        - **Stateless**: Each delete operation is independent\n",
    "        - **Permanent deletion**: Deleted todos cannot be recovered\n",
    "        \n",
    "        **Usage Tips:**\n",
    "        - Use this to remove completed or cancelled todos\n",
    "        - Use this to clean up the todo list\n",
    "        - Use this to remove todos that are no longer needed\n",
    "        - Always verify the ID before deleting\n",
    "        \n",
    "        **Error Handling:**\n",
    "        - If todo not found, check the ID and verify the todo exists\n",
    "        - If you delete by mistake, you'll need to recreate the todo\n",
    "        \n",
    "        Args:\n",
    "            id: ID of the todo to delete\n",
    "        \n",
    "        Returns:\n",
    "            JSON string with success status\n",
    "        \n",
    "        Example:\n",
    "            {\n",
    "                \"success\": true,\n",
    "                \"message\": \"Deleted todo with id '1'\",\n",
    "                \"remaining_count\": 2\n",
    "            }\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Find the todo\n",
    "            todo = None\n",
    "            index = -1\n",
    "            for i, t in enumerate(self._todos):\n",
    "                if t.id == id:\n",
    "                    todo = t\n",
    "                    index = i\n",
    "                    break\n",
    "            \n",
    "            if todo is None:\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Todo with id '{id}' not found\",\n",
    "                }, indent=2)\n",
    "            \n",
    "            # Delete the todo\n",
    "            del self._todos[index]\n",
    "            \n",
    "            return json.dumps({\n",
    "                \"success\": True,\n",
    "                \"message\": f\"Deleted todo with id '{id}'\",\n",
    "                \"remaining_count\": len(self._todos),\n",
    "            }, indent=2)\n",
    "        \n",
    "        except Exception as e:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Failed to delete todo: {str(e)}\",\n",
    "            }, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd58286b-60e6-4c26-9002-8083ffd2de56",
   "metadata": {},
   "source": [
    "Test suite for Todo tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f10cf90-f986-453a-9001-7b5e95ecbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTodoSimple:\n",
    "    \"\"\"Test suite for TodoSimple class.\"\"\"\n",
    "    \n",
    "    def test_initial_state(self):\n",
    "        \"\"\"Test that TodoSimple starts with empty state.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.read_todos())\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"todos\"] == []\n",
    "        assert result[\"total_count\"] == 0\n",
    "        assert result[\"message\"] == \"Retrieved 0 todos\"\n",
    "    \n",
    "    def test_add_todo(self):\n",
    "        \"\"\"Test adding a single todo.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.add_todo(\"1\", \"Test task\"))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"message\"] == \"Added todo with id '1'\"\n",
    "        assert result[\"todo\"][\"id\"] == \"1\"\n",
    "        assert result[\"todo\"][\"content\"] == \"Test task\"\n",
    "        assert result[\"todo\"][\"status\"] == \"PENDING\"\n",
    "        assert result[\"todo\"][\"priority\"] == \"MEDIUM\"\n",
    "    \n",
    "    def test_add_todo_with_status_and_priority(self):\n",
    "        \"\"\"Test adding a todo with custom status and priority.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.add_todo(\"1\", \"Test task\", \"IN_PROGRESS\", \"HIGH\"))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"todo\"][\"status\"] == \"IN_PROGRESS\"\n",
    "        assert result[\"todo\"][\"priority\"] == \"HIGH\"\n",
    "    \n",
    "    def test_add_todo_duplicate_id(self):\n",
    "        \"\"\"Test that adding a todo with duplicate ID fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.add_todo(\"1\", \"Task 2\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"already exists\" in result[\"error\"]\n",
    "    \n",
    "    def test_add_todo_invalid_status(self):\n",
    "        \"\"\"Test that adding a todo with invalid status fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.add_todo(\"1\", \"Test task\", \"INVALID\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"Invalid status\" in result[\"error\"]\n",
    "    \n",
    "    def test_add_todo_invalid_priority(self):\n",
    "        \"\"\"Test that adding a todo with invalid priority fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.add_todo(\"1\", \"Test task\", \"PENDING\", \"INVALID\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"Invalid priority\" in result[\"error\"]\n",
    "    \n",
    "    def test_read_todos_after_adding(self):\n",
    "        \"\"\"Test reading todos after adding some.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        todo.add_todo(\"2\", \"Task 2\")\n",
    "        result = json.loads(todo.read_todos())\n",
    "        assert result[\"success\"] is True\n",
    "        assert len(result[\"todos\"]) == 2\n",
    "        assert result[\"total_count\"] == 2\n",
    "        assert result[\"message\"] == \"Retrieved 2 todos\"\n",
    "    \n",
    "    def test_write_todos(self):\n",
    "        \"\"\"Test writing todos using write_todos method.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todos = [\n",
    "            {\"id\": \"1\", \"content\": \"Task 1\", \"status\": \"PENDING\", \"priority\": \"MEDIUM\"},\n",
    "            {\"id\": \"2\", \"content\": \"Task 2\", \"status\": \"IN_PROGRESS\", \"priority\": \"HIGH\"},\n",
    "        ]\n",
    "        result = json.loads(todo.write_todos(todos))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"total_count\"] == 2\n",
    "        assert len(result[\"todos\"]) == 2\n",
    "    \n",
    "    def test_write_todos_empty_list(self):\n",
    "        \"\"\"Test writing empty list clears todos.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.write_todos([]))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"total_count\"] == 0\n",
    "        assert len(result[\"todos\"]) == 0\n",
    "    \n",
    "    def test_write_todos_none(self):\n",
    "        \"\"\"Test writing None clears todos.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.write_todos(None))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"total_count\"] == 0\n",
    "        assert result[\"message\"] == \"Cleared all todos\"\n",
    "    \n",
    "    def test_write_todos_invalid_input(self):\n",
    "        \"\"\"Test that write_todos with invalid input fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.write_todos(\"invalid\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"todos must be a list\" in result[\"error\"]\n",
    "    \n",
    "    def test_write_todos_missing_fields(self):\n",
    "        \"\"\"Test that write_todos with missing fields fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.write_todos([{\"id\": \"1\"}]))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"fields are required\" in result[\"error\"]\n",
    "    \n",
    "    def test_write_todos_duplicate_ids(self):\n",
    "        \"\"\"Test that write_todos with duplicate IDs fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todos = [\n",
    "            {\"id\": \"1\", \"content\": \"Task 1\"},\n",
    "            {\"id\": \"1\", \"content\": \"Task 2\"},\n",
    "        ]\n",
    "        result = json.loads(todo.write_todos(todos))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"Duplicate todo ID\" in result[\"error\"]\n",
    "    \n",
    "    def test_write_todos_too_many(self):\n",
    "        \"\"\"Test that write_todos with more than 100 todos fails.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todos = [{\"id\": str(i), \"content\": f\"Task {i}\"} for i in range(101)]\n",
    "        result = json.loads(todo.write_todos(todos))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"Cannot store more than 100 todos\" in result[\"error\"]\n",
    "    \n",
    "    def test_update_todo_status(self):\n",
    "        \"\"\"Test updating todo status.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.update_todo_status(\"1\", \"COMPLETED\"))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"message\"] == \"Updated status of todo '1' to COMPLETED\"\n",
    "        assert result[\"todo\"][\"status\"] == \"COMPLETED\"\n",
    "    \n",
    "    def test_update_todo_status_not_found(self):\n",
    "        \"\"\"Test updating status of non-existent todo.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.update_todo_status(\"1\", \"COMPLETED\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"not found\" in result[\"error\"]\n",
    "    \n",
    "    def test_update_todo_status_invalid(self):\n",
    "        \"\"\"Test updating todo status with invalid value.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.update_todo_status(\"1\", \"INVALID\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"Invalid status\" in result[\"error\"]\n",
    "    \n",
    "    def test_update_todo_priority(self):\n",
    "        \"\"\"Test updating todo priority.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.update_todo_status(\"1\", \"COMPLETED\"))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"message\"] == \"Updated status of todo '1' to COMPLETED\"\n",
    "        assert result[\"todo\"][\"status\"] == \"COMPLETED\"\n",
    "    \n",
    "    def test_update_todo_priority_not_found(self):\n",
    "        \"\"\"Test updating priority of non-existent todo.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.update_todo_priority(\"1\", \"HIGH\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"not found\" in result[\"error\"]\n",
    "    \n",
    "    def test_update_todo_priority_invalid(self):\n",
    "        \"\"\"Test updating todo priority with invalid value.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.update_todo_priority(\"1\", \"INVALID\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"Invalid priority\" in result[\"error\"]\n",
    "    \n",
    "    def test_delete_todo(self):\n",
    "        \"\"\"Test deleting a todo.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        todo.add_todo(\"2\", \"Task 2\")\n",
    "        result = json.loads(todo.delete_todo(\"1\"))\n",
    "        assert result[\"success\"] is True\n",
    "        assert result[\"message\"] == \"Deleted todo with id '1'\"\n",
    "        assert result[\"remaining_count\"] == 1\n",
    "        \n",
    "        # Verify the todo is actually deleted\n",
    "        read_result = json.loads(todo.read_todos())\n",
    "        assert len(read_result[\"todos\"]) == 1\n",
    "        assert read_result[\"todos\"][0][\"id\"] == \"2\"\n",
    "    \n",
    "    def test_delete_todo_not_found(self):\n",
    "        \"\"\"Test deleting non-existent todo.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        result = json.loads(todo.delete_todo(\"1\"))\n",
    "        assert result[\"success\"] is False\n",
    "        assert \"not found\" in result[\"error\"]\n",
    "    \n",
    "    def test_json_format_consistency(self):\n",
    "        \"\"\"Test that all methods return valid JSON with consistent format.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        \n",
    "        # Test read_todos\n",
    "        result = todo.read_todos()\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"message\" in data\n",
    "        \n",
    "        # Test add_todo\n",
    "        result = todo.add_todo(\"1\", \"Task 1\")\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"message\" in data\n",
    "        \n",
    "        # Test write_todos\n",
    "        result = todo.write_todos([{\"id\": \"2\", \"content\": \"Task 2\"}])\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"message\" in data\n",
    "        \n",
    "        # Test update_todo_status\n",
    "        result = todo.update_todo_status(\"2\", \"COMPLETED\")\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"message\" in data\n",
    "        \n",
    "        # Test update_todo_priority\n",
    "        result = todo.update_todo_priority(\"2\", \"HIGH\")\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"message\" in data\n",
    "        \n",
    "        # Test delete_todo\n",
    "        result = todo.delete_todo(\"2\")\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"message\" in data\n",
    "    \n",
    "    def test_error_messages_are_actionable(self):\n",
    "        \"\"\"Test that error messages guide users on how to fix issues.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        \n",
    "        # Test duplicate ID error\n",
    "        todo.add_todo(\"1\", \"Task 1\")\n",
    "        result = json.loads(todo.add_todo(\"1\", \"Task 2\"))\n",
    "        assert \"already exists\" in result[\"error\"]\n",
    "        \n",
    "        # Test invalid status error\n",
    "        result = json.loads(todo.add_todo(\"2\", \"Task 2\", \"INVALID\"))\n",
    "        assert \"Invalid status\" in result[\"error\"]\n",
    "        assert \"PENDING, IN_PROGRESS, COMPLETED, CANCELLED\" in result[\"error\"]\n",
    "        \n",
    "        # Test invalid priority error\n",
    "        result = json.loads(todo.add_todo(\"3\", \"Task 3\", \"PENDING\", \"INVALID\"))\n",
    "        assert \"Invalid priority\" in result[\"error\"]\n",
    "        assert \"LOW, MEDIUM, HIGH\" in result[\"error\"]\n",
    "        \n",
    "        # Test not found error\n",
    "        result = json.loads(todo.update_todo_status(\"999\", \"COMPLETED\"))\n",
    "        assert \"not found\" in result[\"error\"]\n",
    "        \n",
    "        # Test too many todos error\n",
    "        todos = [{\"id\": str(i), \"content\": f\"Task {i}\"} for i in range(101)]\n",
    "        result = json.loads(todo.write_todos(todos))\n",
    "        assert \"Cannot store more than 100 todos\" in result[\"error\"]\n",
    "    \n",
    "    def test_todo_status_enum_values(self):\n",
    "        \"\"\"Test that TodoStatus enum has correct values.\"\"\"\n",
    "        assert TodoStatus.PENDING.value == \"PENDING\"\n",
    "        assert TodoStatus.IN_PROGRESS.value == \"IN_PROGRESS\"\n",
    "        assert TodoStatus.COMPLETED.value == \"COMPLETED\"\n",
    "        assert TodoStatus.CANCELLED.value == \"CANCELLED\"\n",
    "    \n",
    "    def test_todo_priority_enum_values(self):\n",
    "        \"\"\"Test that TodoPriority enum has correct values.\"\"\"\n",
    "        assert TodoPriority.LOW.value == \"LOW\"\n",
    "        assert TodoPriority.MEDIUM.value == \"MEDIUM\"\n",
    "        assert TodoPriority.HIGH.value == \"HIGH\"\n",
    "    \n",
    "    def test_todo_item_to_dict(self):\n",
    "        \"\"\"Test that TodoItem.to_dict() returns correct structure.\"\"\"\n",
    "        from todo_simple import TodoItem\n",
    "        todo = TodoItem(\"1\", \"Test\", TodoStatus.IN_PROGRESS, TodoPriority.HIGH)\n",
    "        result = todo.to_dict()\n",
    "        assert result == {\n",
    "            \"id\": \"1\",\n",
    "            \"content\": \"Test\",\n",
    "            \"status\": \"IN_PROGRESS\",\n",
    "            \"priority\": \"HIGH\",\n",
    "        }\n",
    "    \n",
    "    def test_complex_workflow(self):\n",
    "        \"\"\"Test a complex workflow with multiple operations.\"\"\"\n",
    "        todo = TodoSimple()\n",
    "        \n",
    "        # Add multiple todos\n",
    "        todo.add_todo(\"1\", \"Write tests\", \"PENDING\", \"HIGH\")\n",
    "        todo.add_todo(\"2\", \"Review code\", \"PENDING\", \"MEDIUM\")\n",
    "        todo.add_todo(\"3\", \"Fix bugs\", \"IN_PROGRESS\", \"HIGH\")\n",
    "        \n",
    "        # Read all todos\n",
    "        result = json.loads(todo.read_todos())\n",
    "        assert result[\"total_count\"] == 3\n",
    "        \n",
    "        # Update status\n",
    "        todo.update_todo_status(\"1\", \"IN_PROGRESS\")\n",
    "        todo.update_todo_status(\"2\", \"COMPLETED\")\n",
    "        \n",
    "        # Update priority\n",
    "        todo.update_todo_priority(\"3\", \"LOW\")\n",
    "        \n",
    "        # Delete one todo\n",
    "        todo.delete_todo(\"2\")\n",
    "        \n",
    "        # Final state check\n",
    "        result = json.loads(todo.read_todos())\n",
    "        assert result[\"total_count\"] == 2\n",
    "        \n",
    "        # Verify remaining todos\n",
    "        todos_by_id = {t[\"id\"]: t for t in result[\"todos\"]}\n",
    "        assert todos_by_id[\"1\"][\"status\"] == \"IN_PROGRESS\"\n",
    "        assert todos_by_id[\"1\"][\"priority\"] == \"HIGH\"\n",
    "        assert todos_by_id[\"3\"][\"status\"] == \"IN_PROGRESS\"\n",
    "        assert todos_by_id[\"3\"][\"priority\"] == \"LOW\"\n",
    "\n",
    "\n",
    "testTodo = TestTodo()\n",
    "testTodo.test_initial_state()\n",
    "testTodo.test_add_todo()\n",
    "testTodo.test_add_todo_with_status_and_priority()\n",
    "testTodo.test_add_todo_duplicate_id()\n",
    "testTodo.test_add_todo_invalid_status()\n",
    "testTodo.test_add_todo_invalid_priority()\n",
    "testTodo.test_read_todos_after_adding()\n",
    "testTodo.test_write_todos()\n",
    "testTodo.test_write_todos_empty_list()\n",
    "testTodo.test_write_todos_none()\n",
    "testTodo.test_write_todos_invalid_input()\n",
    "testTodo.test_write_todos_missing_fields()\n",
    "testTodo.test_write_todos_duplicate_ids()\n",
    "testTodo.test_write_todos_too_many()\n",
    "testTodo.test_update_todo_status()\n",
    "testTodo.test_update_todo_status_not_found()\n",
    "testTodo.test_update_todo_status_invalid()\n",
    "testTodo.test_update_todo_priority()\n",
    "testTodo.test_update_todo_priority_not_found()\n",
    "testTodo.test_update_todo_priority_invalid()\n",
    "testTodo.test_delete_todo()\n",
    "testTodo.test_delete_todo_not_found()\n",
    "testTodo.test_json_format_consistency()\n",
    "testTodo.test_error_messages_are_actionable()\n",
    "testTodo.test_todo_status_enum_values()\n",
    "testTodo.test_todo_priority_enum_values()\n",
    "testTodo.test_todo_item_to_dict()\n",
    "testTodo.test_complex_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44faa23-1cc6-4376-acef-146ee585ed96",
   "metadata": {},
   "source": [
    "## Tavily API tools\n",
    "\n",
    "### Web search tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233eb6fd-9a09-451e-a107-07f9ed2e2146",
   "metadata": {},
   "source": [
    "Web search tools using Tavily SDK.\n",
    "\n",
    "https://docs.tavily.com/sdk/python/reference\n",
    "\n",
    "These functions return JSON strings that are easy to parse for LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f445eabe-4cce-4f57-a320-3a9cad7ed8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exports\n",
    "\n",
    "# ============================================================================\n",
    "# Web Search Tool\n",
    "# ============================================================================\n",
    "\n",
    "def web_search(\n",
    "    query: str,  # The search query\n",
    "    max_results: int = 5,  # Maximum number of results to return (default: 5)\n",
    "    search_depth: str = \"basic\",  # Search depth: \"basic\" (default) or \"advanced\" (default: \"basic\")\n",
    "    timeout: int = 60  # Timeout in seconds (default: 60)\n",
    ") -> str:  # JSON string with search results or error\n",
    "    \"\"\"\n",
    "    Perform a web search and return results as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each search runs independently in a fresh environment\n",
    "    - **Timeout**: Controls how long the search can run before being cancelled\n",
    "    - When timeout is not specified (or set to None), the config default is used\n",
    "    - If a search is timing out, increase the timeout using the timeout argument\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use specific, focused queries for better results\n",
    "    - Limit max_results to avoid overwhelming the response\n",
    "    - Use \"advanced\" search_depth for more comprehensive but slower searches\n",
    "    - Use \"basic\" search_depth for quick, focused results\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If you get API errors, check:\n",
    "      1. Your API key is valid (set TAVILY_API_KEY environment variable)\n",
    "      2. Your query is not too broad or too narrow\n",
    "      3. You're not hitting rate limits (wait and retry)\n",
    "      4. The timeout is sufficient for the search depth\n",
    "    - Error messages will indicate if the issue is with the API key, query, or timeout\n",
    "    \n",
    "    IMPORTANT: The API key is set via the TAVILY_API_KEY environment variable and should not be\n",
    "    modified by the LLM. Only change other parameters if you encounter errors or failures.\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - max_results: 5 (good for most queries, increase for comprehensive searches)\n",
    "    - search_depth: \"basic\" (faster, use \"advanced\" for more thorough results)\n",
    "    - timeout: 60 seconds (standard timeout, increase if getting timeout errors)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"url\": \"URL of the result\",\n",
    "                \"title\": \"Title of the result\",\n",
    "                \"content\": \"Content snippet\",\n",
    "                \"score\": relevance score,\n",
    "                \"published_date\": \"Publication date\" (optional),\n",
    "                \"favicons\": [\"favicon URLs\"] (optional),\n",
    "                \"raw_content\": \"Full content\" (optional)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "        if api_key is None:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"API key not provided. Please set the TAVILY_API_KEY environment variable.\"\n",
    "            })\n",
    "        \n",
    "        client = TavilyClient(api_key=api_key)\n",
    "        \n",
    "        response = client.search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            search_depth=search_depth,\n",
    "            include_raw_content=True,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"results\": response[\"results\"]\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"401\" in error_msg or \"Unauthorized\" in error_msg:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Invalid API key. Please check your TAVILY_API_KEY and ensure it's valid.\"\n",
    "            })\n",
    "        elif \"429\" in error_msg or \"rate limit\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Rate limit exceeded. Please wait before making more requests or check your Tavily plan.\"\n",
    "            })\n",
    "        elif \"timeout\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Request timed out. Try increasing the timeout parameter (currently {timeout} seconds).\"\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"An error occurred: {error_msg}. Please try again or check your query parameters.\"\n",
    "            })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Web Extract Tool\n",
    "# ============================================================================\n",
    "\n",
    "def web_extract(\n",
    "    urls: List[str],  # List of URLs to extract content from\n",
    "    extract_depth: str = \"low\",  # Extraction depth: \"low\" (default), \"medium\", or \"high\" (default: \"low\")\n",
    "    format: str = \"text\",  # Output format: \"text\" (default) or \"markdown\" (default: \"text\")\n",
    "    timeout: int = 60,  # Timeout in seconds (default: 60)\n",
    "    chunks_per_source: int = 1  # Number of chunks per source (default: 1)\n",
    ") -> str:  # JSON string with extracted content or error\n",
    "    \"\"\"\n",
    "    Extract content from URLs and return as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each extraction runs independently\n",
    "    - **Timeout**: Controls how long the extraction can run before being cancelled\n",
    "    - When timeout is not specified (or set to None), the config default is used\n",
    "    - If extraction is timing out, increase the timeout using the timeout argument\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use \"low\" extract_depth for quick, basic content extraction\n",
    "    - Use \"medium\" or \"high\" for more thorough extraction (slower but more detailed)\n",
    "    - Use \"markdown\" format for formatted output that's easier to read\n",
    "    - Use \"text\" format for plain text (default, works well with most use cases)\n",
    "    - Increase chunks_per_source for more detailed content from each URL\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If you get API errors, check:\n",
    "      1. Your API key is valid (set TAVILY_API_KEY environment variable)\n",
    "      2. The URLs are valid and accessible\n",
    "      3. You're not hitting rate limits (wait and retry)\n",
    "      4. The timeout is sufficient for the extraction depth\n",
    "    - Error messages will indicate if the issue is with the API key, URLs, or timeout\n",
    "    \n",
    "    IMPORTANT: The API key is set via the TAVILY_API_KEY environment variable and should not be\n",
    "    modified by the LLM. Only change other parameters if you encounter errors or failures.\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - extract_depth: \"low\" (default, use \"medium\" or \"high\" for more thorough extraction)\n",
    "    - format: \"text\" (default, use \"markdown\" for formatted output)\n",
    "    - timeout: 60 seconds (default, increase if getting timeout errors)\n",
    "    - chunks_per_source: 1 (default, increase for more detailed content)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"url\": \"URL that was extracted\",\n",
    "                \"content\": \"Extracted content\",\n",
    "                \"chunks\": [\"content chunks\"],\n",
    "                \"word_count\": number of words,\n",
    "                \"errors\": [\"error messages\"] (if any)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "        if api_key is None:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"API key not provided. Please set the TAVILY_API_KEY environment variable.\"\n",
    "            })\n",
    "        \n",
    "        # Validate URLs\n",
    "        if not urls or len(urls) == 0:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"No URLs provided. Please provide at least one URL to extract content from.\"\n",
    "            })\n",
    "        \n",
    "        for url in urls:\n",
    "            if not url.startswith(\"http\"):\n",
    "                return json.dumps({\n",
    "                    \"success\": False,\n",
    "                    \"error\": f\"Invalid URL format: {url}. URLs must start with http:// or https://\"\n",
    "                })\n",
    "        \n",
    "        client = TavilyClient(api_key=api_key)\n",
    "        \n",
    "        response = client.extract_urls(\n",
    "            urls=urls,\n",
    "            extract_depth=extract_depth,\n",
    "            format=format,\n",
    "            timeout=timeout,\n",
    "            chunks_per_source=chunks_per_source\n",
    "        )\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"results\": response[\"results\"]\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"401\" in error_msg or \"Unauthorized\" in error_msg:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Invalid API key. Please check your TAVILY_API_KEY and ensure it's valid.\"\n",
    "            })\n",
    "        elif \"429\" in error_msg or \"rate limit\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Rate limit exceeded. Please wait before making more requests or check your Tavily plan.\"\n",
    "            })\n",
    "        elif \"timeout\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Request timed out. Try increasing the timeout parameter (currently {timeout} seconds).\"\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"An error occurred while extracting content: {error_msg}. Please check the URLs and try again.\"\n",
    "            })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Web Crawl Tool\n",
    "# ============================================================================\n",
    "\n",
    "def web_crawl(\n",
    "    base_url: str,  # The starting URL for crawling\n",
    "    max_depth: int = 1,  # Maximum crawl depth (default: 1)\n",
    "    max_breadth: int = 10,  # Maximum number of pages to crawl (default: 10)\n",
    "    limit: int = 10,  # Maximum number of results (default: 10)\n",
    "    extract_depth: str = \"low\",  # Extraction depth: \"low\" (default), \"medium\", or \"high\" (default: \"low\")\n",
    "    format: str = \"text\",  # Output format: \"text\" (default) or \"markdown\" (default: \"text\")\n",
    "    timeout: int = 60,  # Timeout in seconds (default: 60)\n",
    "    chunks_per_source: int = 1  # Number of chunks per source (default: 1)\n",
    ") -> str:  # JSON string with crawled content or error\n",
    "    \"\"\"\n",
    "    Crawl a website and extract content from pages, returning as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each crawl runs independently\n",
    "    - **Timeout**: Controls how long the crawl can run before being cancelled\n",
    "    - When timeout is not specified (or set to None), the config default is used\n",
    "    - If crawl is timing out, increase the timeout using the timeout argument\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use max_depth=1 for quick crawling of a single page and its direct links\n",
    "    - Use max_depth=2 or 3 for more comprehensive crawling (slower but more thorough)\n",
    "    - Limit max_breadth to avoid crawling too many pages (default 10 is good)\n",
    "    - Limit the total number of results with the limit parameter\n",
    "    - Use \"low\" extract_depth for quick, basic content extraction\n",
    "    - Use \"medium\" or \"high\" for more thorough extraction (slower but more detailed)\n",
    "    - Use \"markdown\" format for formatted output that's easier to read\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If you get API errors, check:\n",
    "      1. Your API key is valid (set TAVILY_API_KEY environment variable)\n",
    "      2. The base URL is valid and accessible\n",
    "      3. You're not hitting rate limits (wait and retry)\n",
    "      4. The timeout is sufficient for the crawl depth and breadth\n",
    "    - Error messages will indicate if the issue is with the API key, URL, or timeout\n",
    "    \n",
    "    IMPORTANT: The API key is set via the TAVILY_API_KEY environment variable and should not be\n",
    "    modified by the LLM. Only change other parameters if you encounter errors or failures.\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - max_depth: 1 (default, good for most websites)\n",
    "    - max_breadth: 10 (default, good balance between coverage and performance)\n",
    "    - limit: 10 (default, good for comprehensive but not excessive crawling)\n",
    "    - extract_depth: \"low\" (default, use \"medium\" or \"high\" for more thorough extraction)\n",
    "    - format: \"text\" (default, use \"markdown\" for formatted output)\n",
    "    - timeout: 60 seconds (default, increase if getting timeout errors)\n",
    "    - chunks_per_source: 1 (default, increase for more detailed content)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"url\": \"URL that was crawled\",\n",
    "                \"title\": \"Page title\",\n",
    "                \"content\": \"Extracted content\",\n",
    "                \"depth\": crawl depth,\n",
    "                \"word_count\": number of words,\n",
    "                \"errors\": [\"error messages\"] (if any)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "        if api_key is None:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"API key not provided. Please set the TAVILY_API_KEY environment variable.\"\n",
    "            })\n",
    "        \n",
    "        # Validate base URL\n",
    "        if not base_url.startswith(\"http\"):\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Invalid base URL format: {base_url}. URLs must start with http:// or https://\"\n",
    "            })\n",
    "        \n",
    "        client = TavilyClient(api_key=api_key)\n",
    "        \n",
    "        response = client.crawl_base_url(\n",
    "            base_url=base_url,\n",
    "            max_depth=max_depth,\n",
    "            max_breadth=max_breadth,\n",
    "            limit=limit,\n",
    "            extract_depth=extract_depth,\n",
    "            format=format,\n",
    "            timeout=timeout,\n",
    "            chunks_per_source=chunks_per_source\n",
    "        )\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"results\": response[\"results\"]\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"401\" in error_msg or \"Unauthorized\" in error_msg:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Invalid API key. Please check your TAVILY_API_KEY and ensure it's valid.\"\n",
    "            })\n",
    "        elif \"429\" in error_msg or \"rate limit\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Rate limit exceeded. Please wait before making more requests or check your Tavily plan.\"\n",
    "            })\n",
    "        elif \"timeout\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Request timed out. Try increasing the timeout parameter (currently {timeout} seconds).\"\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"An error occurred while crawling: {error_msg}. Please check the base URL and try again.\"\n",
    "            })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Web Map Tool\n",
    "# ============================================================================\n",
    "\n",
    "def web_map(\n",
    "    base_url: str,  # The starting URL for sitemap generation\n",
    "    max_depth: int = 1,  # Maximum crawl depth (default: 1)\n",
    "    max_breadth: int = 10,  # Maximum number of pages to discover (default: 10)\n",
    "    limit: int = 10,  # Maximum number of URLs to return (default: 10)\n",
    "    timeout: int = 60  # Timeout in seconds (default: 60)\n",
    ") -> str:  # JSON string with sitemap or error\n",
    "    \"\"\"\n",
    "    Generate a sitemap by discovering URLs on a website, returning as JSON.\n",
    "    \n",
    "    **Key characteristics:**\n",
    "    - **Stateless**: Each sitemap generation runs independently\n",
    "    - **Timeout**: Controls how long the sitemap generation can run before being cancelled\n",
    "    - When timeout is not specified (or set to None), the config default is used\n",
    "    - If sitemap generation is timing out, increase the timeout using the timeout argument\n",
    "    \n",
    "    **Usage Tips:**\n",
    "    - Use max_depth=1 for quick discovery of a single page and its direct links\n",
    "    - Use max_depth=2 or 3 for more comprehensive sitemap generation (slower but more thorough)\n",
    "    - Limit max_breadth to avoid discovering too many URLs (default 10 is good)\n",
    "    - Limit the total number of URLs with the limit parameter\n",
    "    \n",
    "    **Error Handling:**\n",
    "    - If you get API errors, check:\n",
    "      1. Your API key is valid (set TAVILY_API_KEY environment variable)\n",
    "      2. The base URL is valid and accessible\n",
    "      3. You're not hitting rate limits (wait and retry)\n",
    "      4. The timeout is sufficient for the sitemap depth and breadth\n",
    "    - Error messages will indicate if the issue is with the API key, URL, or timeout\n",
    "    \n",
    "    IMPORTANT: The API key is set via the TAVILY_API_KEY environment variable and should not be\n",
    "    modified by the LLM. Only change other parameters if you encounter errors or failures.\n",
    "    \n",
    "    Default values are optimized for general use:\n",
    "    - max_depth: 1 (default, good for most websites)\n",
    "    - max_breadth: 10 (default, good balance between coverage and performance)\n",
    "    - limit: 10 (default, good for comprehensive but not excessive mapping)\n",
    "    - timeout: 60 seconds (default, increase if getting timeout errors)\n",
    "    \n",
    "    Returns JSON with format:\n",
    "    {\n",
    "        \"success\": true/false,\n",
    "        \"error\": \"error message\" (only if success=false),\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"url\": \"Discovered URL\",\n",
    "                \"title\": \"Page title\" (optional),\n",
    "                \"depth\": discovery depth,\n",
    "                \"status_code\": HTTP status code,\n",
    "                \"errors\": [\"error messages\"] (if any)\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    Error messages will guide the LLM on how to fix the issue.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get API key from environment\n",
    "        api_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "        if api_key is None:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"API key not provided. Please set the TAVILY_API_KEY environment variable.\"\n",
    "            })\n",
    "        \n",
    "        # Validate base URL\n",
    "        if not base_url.startswith(\"http\"):\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Invalid base URL format: {base_url}. URLs must start with http:// or https://\"\n",
    "            })\n",
    "        \n",
    "        client = TavilyClient(api_key=api_key)\n",
    "        \n",
    "        response = client.sitemap(\n",
    "            base_url=base_url,\n",
    "            max_depth=max_depth,\n",
    "            max_breadth=max_breadth,\n",
    "            limit=limit,\n",
    "            timeout=timeout\n",
    "        )\n",
    "        \n",
    "        return json.dumps({\n",
    "            \"success\": True,\n",
    "            \"results\": response[\"results\"]\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if \"401\" in error_msg or \"Unauthorized\" in error_msg:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Invalid API key. Please check your TAVILY_API_KEY and ensure it's valid.\"\n",
    "            })\n",
    "        elif \"429\" in error_msg or \"rate limit\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": \"Rate limit exceeded. Please wait before making more requests or check your Tavily plan.\"\n",
    "            })\n",
    "        elif \"timeout\" in error_msg.lower():\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"Request timed out. Try increasing the timeout parameter (currently {timeout} seconds).\"\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\n",
    "                \"success\": False,\n",
    "                \"error\": f\"An error occurred while generating sitemap: {error_msg}. Please check the base URL and try again.\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d931ec8-d17d-46b6-b0e3-126352bece31",
   "metadata": {},
   "source": [
    "Test suite for web search tools.\n",
    "\n",
    "Tests both functionality and error handling with JSON return format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac5312-e4a6-4b38-b11f-fb3b38fb454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytest\n",
    "import json\n",
    "from unittest.mock import Mock, patch, MagicMock\n",
    "\n",
    "# ============================================================================\n",
    "# Test Web Search\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_web_search_with_api_key():\n",
    "    \"\"\"Test web_search with explicit API key returns JSON\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\n",
    "            \"results\": [\n",
    "                {\"url\": \"https://example.com\", \"title\": \"Example\", \"content\": \"Test content\"}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Call function\n",
    "        result = web_search(\n",
    "            query=\"test query\",\n",
    "            api_key=\"test-api-key\",\n",
    "            max_results=5\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"results\"]) == 1\n",
    "        assert data[\"results\"][0][\"url\"] == \"https://example.com\"\n",
    "        assert \"error\" not in data\n",
    "\n",
    "\n",
    "def test_web_search_with_env_api_key():\n",
    "    \"\"\"Test web_search with API key from environment variable\"\"\"\n",
    "    with patch.dict(os.environ, {\"TAVILY_API_KEY\": \"env-api-key\"}), \\\n",
    "         patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        \n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\n",
    "            \"results\": [{\"url\": \"https://example.com\", \"title\": \"Example\"}]\n",
    "        }\n",
    "        \n",
    "        # Call function without api_key parameter\n",
    "        result = web_search(query=\"test query\")\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"results\"]) == 1\n",
    "        mock_client.assert_called_once_with(api_key=\"env-api-key\")\n",
    "\n",
    "\n",
    "def test_web_search_missing_api_key():\n",
    "    \"\"\"Test web_search returns error JSON when API key is missing\"\"\"\n",
    "    with patch.dict(os.environ, {}, clear=True):\n",
    "        result = web_search(query=\"test query\")\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"API key not provided\" in data[\"error\"]\n",
    "        assert \"TAVILY_API_KEY\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_search_custom_params():\n",
    "    \"\"\"Test web_search with custom parameters\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call with custom params\n",
    "        result = web_search(\n",
    "            query=\"custom query\",\n",
    "            api_key=\"test-key\",\n",
    "            max_results=10,\n",
    "            search_depth=\"advanced\",\n",
    "            timeout=120\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_instance.search.assert_called_once_with(\n",
    "            query=\"custom query\",\n",
    "            max_results=10,\n",
    "            search_depth=\"advanced\",\n",
    "            include_raw_content=True,\n",
    "            timeout=120\n",
    "        )\n",
    "\n",
    "\n",
    "def test_web_search_unauthorized_error():\n",
    "    \"\"\"Test web_search returns helpful error for unauthorized\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise 401 error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.side_effect = Exception(\"401 Unauthorized\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_search(query=\"test\" )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"Invalid API key\" in data[\"error\"]\n",
    "        assert \"TAVILY_API_KEY\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_search_rate_limit_error():\n",
    "    \"\"\"Test web_search returns helpful error for rate limit\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise rate limit error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.side_effect = Exception(\"429 Too Many Requests\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_search(query=\"test\" )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"rate limit\" in data[\"error\"].lower()\n",
    "\n",
    "\n",
    "def test_web_search_timeout_error():\n",
    "    \"\"\"Test web_search returns helpful error for timeout\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise timeout error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.side_effect = Exception(\"Timeout after 60 seconds\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_search(query=\"test\" , timeout=60)\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"timeout\" in data[\"error\"].lower()\n",
    "        assert \"60 seconds\" in data[\"error\"]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Test Web Extract\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_web_extract_with_api_key():\n",
    "    \"\"\"Test web_extract with explicit API key returns JSON\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.extract_urls.return_value = {\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"url\": \"https://example.com\",\n",
    "                    \"content\": \"Extracted content\",\n",
    "                    \"word_count\": 100\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Call function\n",
    "        result = web_extract(\n",
    "            urls=[\"https://example.com\"],\n",
    "            api_key=\"test-api-key\"\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"results\"]) == 1\n",
    "        assert data[\"results\"][0][\"url\"] == \"https://example.com\"\n",
    "        assert \"error\" not in data\n",
    "\n",
    "\n",
    "def test_web_extract_with_env_api_key():\n",
    "    \"\"\"Test web_extract with API key from environment variable\"\"\"\n",
    "    with patch.dict(os.environ, {\"TAVILY_API_KEY\": \"env-api-key\"}), \\\n",
    "         patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        \n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.extract_urls.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call function without api_key parameter\n",
    "        result = web_extract(urls=[\"https://example.com\"])\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_client.assert_called_once_with(api_key=\"env-api-key\")\n",
    "\n",
    "\n",
    "def test_web_extract_empty_urls():\n",
    "    \"\"\"Test web_extract returns error for empty URLs list\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        result = web_extract(urls=[] )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"No URLs provided\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_extract_invalid_url():\n",
    "    \"\"\"Test web_extract returns error for invalid URL format\"\"\"\n",
    "    result = web_extract(urls=[\"example.com\"] )\n",
    "    \n",
    "    # Parse JSON\n",
    "    data = json.loads(result)\n",
    "    \n",
    "    # Assertions\n",
    "    assert data[\"success\"] is False\n",
    "    assert \"error\" in data\n",
    "    assert \"Invalid URL format\" in data[\"error\"]\n",
    "    assert \"http\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_extract_custom_params():\n",
    "    \"\"\"Test web_extract with custom parameters\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.extract_urls.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call with custom params\n",
    "        result = web_extract(\n",
    "            urls=[\"https://example.com\", \"https://example.org\"],\n",
    "            api_key=\"test-key\",\n",
    "            extract_depth=\"high\",\n",
    "            format=\"markdown\",\n",
    "            timeout=90,\n",
    "            chunks_per_source=3\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_instance.extract_urls.assert_called_once_with(\n",
    "            urls=[\"https://example.com\", \"https://example.org\"],\n",
    "            extract_depth=\"high\",\n",
    "            format=\"markdown\",\n",
    "            timeout=90,\n",
    "            chunks_per_source=3\n",
    "        )\n",
    "\n",
    "\n",
    "def test_web_extract_unauthorized_error():\n",
    "    \"\"\"Test web_extract returns helpful error for unauthorized\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise 401 error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.extract_urls.side_effect = Exception(\"401 Unauthorized\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_extract(urls=[\"https://example.com\"] )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"Invalid API key\" in data[\"error\"]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Test Web Crawl\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_web_crawl_with_api_key():\n",
    "    \"\"\"Test web_crawl with explicit API key returns JSON\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.crawl_base_url.return_value = {\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"url\": \"https://example.com/page1\",\n",
    "                    \"title\": \"Page 1\",\n",
    "                    \"content\": \"Content 1\",\n",
    "                    \"depth\": 0\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Call function\n",
    "        result = web_crawl(\n",
    "            base_url=\"https://example.com\",\n",
    "            api_key=\"test-api-key\"\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"results\"]) == 1\n",
    "        assert data[\"results\"][0][\"url\"] == \"https://example.com/page1\"\n",
    "        assert \"error\" not in data\n",
    "\n",
    "\n",
    "def test_web_crawl_invalid_base_url():\n",
    "    \"\"\"Test web_crawl returns error for invalid base URL format\"\"\"\n",
    "    result = web_crawl(base_url=\"example.com\" )\n",
    "    \n",
    "    # Parse JSON\n",
    "    data = json.loads(result)\n",
    "    \n",
    "    # Assertions\n",
    "    assert data[\"success\"] is False\n",
    "    assert \"error\" in data\n",
    "    assert \"Invalid base URL format\" in data[\"error\"]\n",
    "    assert \"http\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_crawl_with_env_api_key():\n",
    "    \"\"\"Test web_crawl with API key from environment variable\"\"\"\n",
    "    with patch.dict(os.environ, {\"TAVILY_API_KEY\": \"env-api-key\"}), \\\n",
    "         patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        \n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.crawl_base_url.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call function without api_key parameter\n",
    "        result = web_crawl(base_url=\"https://example.com\")\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_client.assert_called_once_with(api_key=\"env-api-key\")\n",
    "\n",
    "\n",
    "def test_web_crawl_custom_params():\n",
    "    \"\"\"Test web_crawl with custom parameters\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.crawl_base_url.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call with custom params\n",
    "        result = web_crawl(\n",
    "            base_url=\"https://example.com\",\n",
    "            api_key=\"test-key\",\n",
    "            max_depth=2,\n",
    "            max_breadth=20,\n",
    "            limit=5,\n",
    "            extract_depth=\"medium\",\n",
    "            format=\"markdown\",\n",
    "            timeout=180,\n",
    "            chunks_per_source=2\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_instance.crawl_base_url.assert_called_once_with(\n",
    "            base_url=\"https://example.com\",\n",
    "            max_depth=2,\n",
    "            max_breadth=20,\n",
    "            limit=5,\n",
    "            extract_depth=\"medium\",\n",
    "            format=\"markdown\",\n",
    "            timeout=180,\n",
    "            chunks_per_source=2\n",
    "        )\n",
    "\n",
    "\n",
    "def test_web_crawl_unauthorized_error():\n",
    "    \"\"\"Test web_crawl returns helpful error for unauthorized\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise 401 error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.crawl_base_url.side_effect = Exception(\"401 Unauthorized\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_crawl(base_url=\"https://example.com\" )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"Invalid API key\" in data[\"error\"]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Test Web Map\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_web_map_with_api_key():\n",
    "    \"\"\"Test web_map with explicit API key returns JSON\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.sitemap.return_value = {\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"url\": \"https://example.com/page1\",\n",
    "                    \"title\": \"Page 1\",\n",
    "                    \"depth\": 0,\n",
    "                    \"status_code\": 200\n",
    "                },\n",
    "                {\n",
    "                    \"url\": \"https://example.com/page2\",\n",
    "                    \"title\": \"Page 2\",\n",
    "                    \"depth\": 0,\n",
    "                    \"status_code\": 200\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # Call function\n",
    "        result = web_map(\n",
    "            base_url=\"https://example.com\",\n",
    "            api_key=\"test-api-key\"\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"results\"]) == 2\n",
    "        assert data[\"results\"][0][\"url\"] == \"https://example.com/page1\"\n",
    "        assert \"error\" not in data\n",
    "\n",
    "\n",
    "def test_web_map_invalid_base_url():\n",
    "    \"\"\"Test web_map returns error for invalid base URL format\"\"\"\n",
    "    result = web_map(base_url=\"example.com\" )\n",
    "    \n",
    "    # Parse JSON\n",
    "    data = json.loads(result)\n",
    "    \n",
    "    # Assertions\n",
    "    assert data[\"success\"] is False\n",
    "    assert \"error\" in data\n",
    "    assert \"Invalid base URL format\" in data[\"error\"]\n",
    "    assert \"http\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_map_with_env_api_key():\n",
    "    \"\"\"Test web_map with API key from environment variable\"\"\"\n",
    "    with patch.dict(os.environ, {\"TAVILY_API_KEY\": \"env-api-key\"}), \\\n",
    "         patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        \n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.sitemap.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call function without api_key parameter\n",
    "        result = web_map(base_url=\"https://example.com\")\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_client.assert_called_once_with(api_key=\"env-api-key\")\n",
    "\n",
    "\n",
    "def test_web_map_custom_params():\n",
    "    \"\"\"Test web_map with custom parameters\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.sitemap.return_value = {\"results\": []}\n",
    "        \n",
    "        # Call with custom params\n",
    "        result = web_map(\n",
    "            base_url=\"https://example.com\",\n",
    "            api_key=\"test-key\",\n",
    "            max_depth=3,\n",
    "            max_breadth=50,\n",
    "            limit=25,\n",
    "            timeout=300\n",
    "        )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is True\n",
    "        mock_instance.sitemap.assert_called_once_with(\n",
    "            base_url=\"https://example.com\",\n",
    "            max_depth=3,\n",
    "            max_breadth=50,\n",
    "            limit=25,\n",
    "            timeout=300\n",
    "        )\n",
    "\n",
    "\n",
    "def test_web_map_unauthorized_error():\n",
    "    \"\"\"Test web_map returns helpful error for unauthorized\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise 401 error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.sitemap.side_effect = Exception(\"401 Unauthorized\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_map(base_url=\"https://example.com\" )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"Invalid API key\" in data[\"error\"]\n",
    "\n",
    "\n",
    "def test_web_map_rate_limit_error():\n",
    "    \"\"\"Test web_map returns helpful error for rate limit\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        # Setup mock to raise rate limit error\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.sitemap.side_effect = Exception(\"Rate limit exceeded\")\n",
    "        \n",
    "        # Call function\n",
    "        result = web_map(base_url=\"https://example.com\" )\n",
    "        \n",
    "        # Parse JSON\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        # Assertions\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert \"rate limit\" in data[\"error\"].lower()\n",
    "        assert \"wait\" in data[\"error\"].lower()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Test Error Handling\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_all_tools_error_without_api_key():\n",
    "    \"\"\"Test all tools return error JSON when API key is missing\"\"\"\n",
    "    with patch.dict(os.environ, {}, clear=True):\n",
    "        # Test web_search\n",
    "        result = web_search(query=\"test\")\n",
    "        data = json.loads(result)\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        \n",
    "        # Test web_extract\n",
    "        result = web_extract(urls=[\"https://example.com\"])\n",
    "        data = json.loads(result)\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        \n",
    "        # Test web_crawl\n",
    "        result = web_crawl(base_url=\"https://example.com\")\n",
    "        data = json.loads(result)\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        \n",
    "        # Test web_map\n",
    "        result = web_map(base_url=\"https://example.com\")\n",
    "        data = json.loads(result)\n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "\n",
    "\n",
    "def test_all_tools_use_env_api_key():\n",
    "    \"\"\"Test all tools can use API key from environment\"\"\"\n",
    "    with patch.dict(os.environ, {\"TAVILY_API_KEY\": \"env-key\"}), \\\n",
    "         patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        \n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\"results\": []}\n",
    "        mock_instance.extract_urls.return_value = {\"results\": []}\n",
    "        mock_instance.crawl_base_url.return_value = {\"results\": []}\n",
    "        mock_instance.sitemap.return_value = {\"results\": []}\n",
    "        \n",
    "        # All should work without explicit api_key\n",
    "        result = web_search(query=\"test\")\n",
    "        assert json.loads(result)[\"success\"] is True\n",
    "        \n",
    "        result = web_extract(urls=[\"https://example.com\"])\n",
    "        assert json.loads(result)[\"success\"] is True\n",
    "        \n",
    "        result = web_crawl(base_url=\"https://example.com\")\n",
    "        assert json.loads(result)[\"success\"] is True\n",
    "        \n",
    "        result = web_map(base_url=\"https://example.com\")\n",
    "        assert json.loads(result)[\"success\"] is True\n",
    "        \n",
    "        # All should use the env key\n",
    "        assert mock_client.call_count == 4\n",
    "        for call in mock_client.call_args_list:\n",
    "            assert call[1]['api_key'] == 'env-key'\n",
    "\n",
    "\n",
    "def test_error_messages_are_helpful():\n",
    "    \"\"\"Test that error messages guide the LLM on how to fix issues\"\"\"\n",
    "    with patch.dict(os.environ, {}, clear=True):\n",
    "        # Test missing API key\n",
    "        result = web_search(query=\"test\")\n",
    "        data = json.loads(result)\n",
    "        assert \"TAVILY_API_KEY\" in data[\"error\"]\n",
    "        assert \"environment variable\" in data[\"error\"].lower()\n",
    "        \n",
    "        # Test invalid URL format\n",
    "        # First set API key to test URL validation\n",
    "        os.environ[\"TAVILY_API_KEY\"] = \"test-key\"\n",
    "        result = web_extract(urls=[\"example.com\"] )\n",
    "        data = json.loads(result)\n",
    "        assert \"http\" in data[\"error\"].lower()\n",
    "        \n",
    "        # Test invalid base URL format\n",
    "        result = web_crawl(base_url=\"example.com\" )\n",
    "        data = json.loads(result)\n",
    "        assert \"http\" in data[\"error\"].lower()\n",
    "        \n",
    "        # Clean up\n",
    "        del os.environ[\"TAVILY_API_KEY\"]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Test JSON Format\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_all_tools_return_valid_json():\n",
    "    \"\"\"Test all tools return valid JSON strings\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\"results\": []}\n",
    "        mock_instance.extract_urls.return_value = {\"results\": []}\n",
    "        mock_instance.crawl_base_url.return_value = {\"results\": []}\n",
    "        mock_instance.sitemap.return_value = {\"results\": []}\n",
    "        \n",
    "        # Test web_search\n",
    "        result = web_search(query=\"test\" )\n",
    "        assert isinstance(result, str)\n",
    "        json.loads(result)  # Should not raise\n",
    "        \n",
    "        # Test web_extract\n",
    "        result = web_extract(urls=[\"https://example.com\"] )\n",
    "        assert isinstance(result, str)\n",
    "        json.loads(result)  # Should not raise\n",
    "        \n",
    "        # Test web_crawl\n",
    "        result = web_crawl(base_url=\"https://example.com\" )\n",
    "        assert isinstance(result, str)\n",
    "        json.loads(result)  # Should not raise\n",
    "        \n",
    "        # Test web_map\n",
    "        result = web_map(base_url=\"https://example.com\" )\n",
    "        assert isinstance(result, str)\n",
    "        json.loads(result)  # Should not raise\n",
    "\n",
    "\n",
    "def test_json_has_required_fields():\n",
    "    \"\"\"Test JSON responses have required fields\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\n",
    "            \"results\": [{\"url\": \"https://example.com\", \"title\": \"Test\"}]\n",
    "        }\n",
    "        \n",
    "        # Test success response\n",
    "        result = web_search(query=\"test\" )\n",
    "        data = json.loads(result)\n",
    "        assert \"success\" in data\n",
    "        assert \"results\" in data\n",
    "        assert data[\"success\"] is True\n",
    "        \n",
    "        # Test error response (with no API key and no env var)\n",
    "        with patch.dict(os.environ, {}, clear=True):\n",
    "            result = web_search(query=\"test\")\n",
    "            data = json.loads(result)\n",
    "            assert \"success\" in data\n",
    "            assert \"error\" in data\n",
    "            assert data[\"success\"] is False\n",
    "\n",
    "\n",
    "def test_json_error_format():\n",
    "    \"\"\"Test error responses have consistent format\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.side_effect = Exception(\"Test error\")\n",
    "        \n",
    "        result = web_search(query=\"test\" )\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is False\n",
    "        assert \"error\" in data\n",
    "        assert isinstance(data[\"error\"], str)\n",
    "        assert len(data[\"error\"]) > 0\n",
    "        assert \"Test error\" in data[\"error\"]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Test Edge Cases\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def test_web_search_empty_results():\n",
    "    \"\"\"Test web_search with empty results\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.search.return_value = {\"results\": []}\n",
    "        \n",
    "        result = web_search(query=\"test\" )\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert data[\"results\"] == []\n",
    "\n",
    "\n",
    "def test_web_extract_multiple_urls():\n",
    "    \"\"\"Test web_extract with multiple URLs\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.extract_urls.return_value = {\n",
    "            \"results\": [\n",
    "                {\"url\": \"https://example.com\", \"content\": \"Content 1\"},\n",
    "                {\"url\": \"https://example.org\", \"content\": \"Content 2\"}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = web_extract(\n",
    "            urls=[\"https://example.com\", \"https://example.org\"],\n",
    "            api_key=\"test-key\"\n",
    "        )\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        assert len(data[\"results\"]) == 2\n",
    "        assert data[\"results\"][0][\"url\"] == \"https://example.com\"\n",
    "        assert data[\"results\"][1][\"url\"] == \"https://example.org\"\n",
    "\n",
    "\n",
    "def test_web_crawl_with_limit():\n",
    "    \"\"\"Test web_crawl respects limit parameter\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.crawl_base_url.return_value = {\n",
    "            \"results\": [\n",
    "                {\"url\": f\"https://example.com/page{i}\"} for i in range(5)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = web_crawl(\n",
    "            base_url=\"https://example.com\",\n",
    "            api_key=\"test-key\",\n",
    "            limit=3\n",
    "        )\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        mock_instance.crawl_base_url.assert_called_once()\n",
    "        call_kwargs = mock_instance.crawl_base_url.call_args[1]\n",
    "        assert call_kwargs['limit'] == 3\n",
    "\n",
    "\n",
    "def test_web_map_with_limit():\n",
    "    \"\"\"Test web_map respects limit parameter\"\"\"\n",
    "    with patch('web_search_simple.TavilyClient') as mock_client:\n",
    "        mock_instance = mock_client.return_value\n",
    "        mock_instance.sitemap.return_value = {\n",
    "            \"results\": [\n",
    "                {\"url\": f\"https://example.com/page{i}\"} for i in range(10)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        result = web_map(\n",
    "            base_url=\"https://example.com\",\n",
    "            api_key=\"test-key\",\n",
    "            limit=5\n",
    "        )\n",
    "        data = json.loads(result)\n",
    "        \n",
    "        assert data[\"success\"] is True\n",
    "        mock_instance.sitemap.assert_called_once()\n",
    "        call_kwargs = mock_instance.sitemap.call_args[1]\n",
    "        assert call_kwargs['limit'] == 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wordslab-notebooks-lib",
   "language": "python",
   "name": "wordslab-notebooks-lib"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
